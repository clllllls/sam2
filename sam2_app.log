2025-11-20 10:40:04,191 - __main__ - INFO - 启动SAM2应用程序
2025-11-20 10:40:04,343 - __main__ - INFO - 应用程序窗口已显示
2025-11-20 10:40:44,720 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:44,720 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:44,721 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:44,721 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:45,280 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:45,280 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:45,281 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:45,281 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:45,680 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:45,680 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:45,681 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:45,681 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:46,088 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:46,088 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:46,089 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:46,089 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:46,736 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:46,736 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:46,737 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:46,737 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,136 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,136 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,137 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,137 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,560 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,560 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,561 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,561 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,824 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,824 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:47,825 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:47,825 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:52,160 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:52,161 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-20 10:40:52,161 - __main__ - INFO - 开始设置图像: , 保留视图状态: True
2025-11-20 10:40:52,161 - __main__ - ERROR - 加载图像出错: 文件不存在 - 
2025-11-27 14:14:09,962 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:14:10,112 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:14:29,153 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:22:46,131 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:22:46,264 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:22:56,591 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:25:07,432 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:25:07,551 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:25:18,073 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:25:18,667 - __main__ - ERROR - 加载模型出错: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "maskmem_tpos_enc", "no_mem_embed", "no_mem_pos_enc", "no_obj_ptr", "no_obj_embed_spatial", "image_encoder.trunk.pos_embed", "image_encoder.trunk.pos_embed_window", "image_encoder.trunk.patch_embed.proj.weight", "image_encoder.trunk.patch_embed.proj.bias", "image_encoder.trunk.blocks.0.norm1.weight", "image_encoder.trunk.blocks.0.norm1.bias", "image_encoder.trunk.blocks.0.attn.qkv.weight", "image_encoder.trunk.blocks.0.attn.qkv.bias", "image_encoder.trunk.blocks.0.attn.proj.weight", "image_encoder.trunk.blocks.0.attn.proj.bias", "image_encoder.trunk.blocks.0.norm2.weight", "image_encoder.trunk.blocks.0.norm2.bias", "image_encoder.trunk.blocks.0.mlp.layers.0.weight", "image_encoder.trunk.blocks.0.mlp.layers.0.bias", "image_encoder.trunk.blocks.0.mlp.layers.1.weight", "image_encoder.trunk.blocks.0.mlp.layers.1.bias", "image_encoder.trunk.blocks.1.norm1.weight", "image_encoder.trunk.blocks.1.norm1.bias", "image_encoder.trunk.blocks.1.attn.qkv.weight", "image_encoder.trunk.blocks.1.attn.qkv.bias", "image_encoder.trunk.blocks.1.attn.proj.weight", "image_encoder.trunk.blocks.1.attn.proj.bias", "image_encoder.trunk.blocks.1.norm2.weight", "image_encoder.trunk.blocks.1.norm2.bias", "image_encoder.trunk.blocks.1.mlp.layers.0.weight", "image_encoder.trunk.blocks.1.mlp.layers.0.bias", "image_encoder.trunk.blocks.1.mlp.layers.1.weight", "image_encoder.trunk.blocks.1.mlp.layers.1.bias", "image_encoder.trunk.blocks.2.norm1.weight", "image_encoder.trunk.blocks.2.norm1.bias", "image_encoder.trunk.blocks.2.attn.qkv.weight", "image_encoder.trunk.blocks.2.attn.qkv.bias", "image_encoder.trunk.blocks.2.attn.proj.weight", "image_encoder.trunk.blocks.2.attn.proj.bias", "image_encoder.trunk.blocks.2.norm2.weight", "image_encoder.trunk.blocks.2.norm2.bias", "image_encoder.trunk.blocks.2.mlp.layers.0.weight", "image_encoder.trunk.blocks.2.mlp.layers.0.bias", "image_encoder.trunk.blocks.2.mlp.layers.1.weight", "image_encoder.trunk.blocks.2.mlp.layers.1.bias", "image_encoder.trunk.blocks.2.proj.weight", "image_encoder.trunk.blocks.2.proj.bias", "image_encoder.trunk.blocks.3.norm1.weight", "image_encoder.trunk.blocks.3.norm1.bias", "image_encoder.trunk.blocks.3.attn.qkv.weight", "image_encoder.trunk.blocks.3.attn.qkv.bias", "image_encoder.trunk.blocks.3.attn.proj.weight", "image_encoder.trunk.blocks.3.attn.proj.bias", "image_encoder.trunk.blocks.3.norm2.weight", "image_encoder.trunk.blocks.3.norm2.bias", "image_encoder.trunk.blocks.3.mlp.layers.0.weight", "image_encoder.trunk.blocks.3.mlp.layers.0.bias", "image_encoder.trunk.blocks.3.mlp.layers.1.weight", "image_encoder.trunk.blocks.3.mlp.layers.1.bias", "image_encoder.trunk.blocks.4.norm1.weight", "image_encoder.trunk.blocks.4.norm1.bias", "image_encoder.trunk.blocks.4.attn.qkv.weight", "image_encoder.trunk.blocks.4.attn.qkv.bias", "image_encoder.trunk.blocks.4.attn.proj.weight", "image_encoder.trunk.blocks.4.attn.proj.bias", "image_encoder.trunk.blocks.4.norm2.weight", "image_encoder.trunk.blocks.4.norm2.bias", "image_encoder.trunk.blocks.4.mlp.layers.0.weight", "image_encoder.trunk.blocks.4.mlp.layers.0.bias", "image_encoder.trunk.blocks.4.mlp.layers.1.weight", "image_encoder.trunk.blocks.4.mlp.layers.1.bias", "image_encoder.trunk.blocks.5.norm1.weight", "image_encoder.trunk.blocks.5.norm1.bias", "image_encoder.trunk.blocks.5.attn.qkv.weight", "image_encoder.trunk.blocks.5.attn.qkv.bias", "image_encoder.trunk.blocks.5.attn.proj.weight", "image_encoder.trunk.blocks.5.attn.proj.bias", "image_encoder.trunk.blocks.5.norm2.weight", "image_encoder.trunk.blocks.5.norm2.bias", "image_encoder.trunk.blocks.5.mlp.layers.0.weight", "image_encoder.trunk.blocks.5.mlp.layers.0.bias", "image_encoder.trunk.blocks.5.mlp.layers.1.weight", "image_encoder.trunk.blocks.5.mlp.layers.1.bias", "image_encoder.trunk.blocks.5.proj.weight", "image_encoder.trunk.blocks.5.proj.bias", "image_encoder.trunk.blocks.6.norm1.weight", "image_encoder.trunk.blocks.6.norm1.bias", "image_encoder.trunk.blocks.6.attn.qkv.weight", "image_encoder.trunk.blocks.6.attn.qkv.bias", "image_encoder.trunk.blocks.6.attn.proj.weight", "image_encoder.trunk.blocks.6.attn.proj.bias", "image_encoder.trunk.blocks.6.norm2.weight", "image_encoder.trunk.blocks.6.norm2.bias", "image_encoder.trunk.blocks.6.mlp.layers.0.weight", "image_encoder.trunk.blocks.6.mlp.layers.0.bias", "image_encoder.trunk.blocks.6.mlp.layers.1.weight", "image_encoder.trunk.blocks.6.mlp.layers.1.bias", "image_encoder.trunk.blocks.7.norm1.weight", "image_encoder.trunk.blocks.7.norm1.bias", "image_encoder.trunk.blocks.7.attn.qkv.weight", "image_encoder.trunk.blocks.7.attn.qkv.bias", "image_encoder.trunk.blocks.7.attn.proj.weight", "image_encoder.trunk.blocks.7.attn.proj.bias", "image_encoder.trunk.blocks.7.norm2.weight", "image_encoder.trunk.blocks.7.norm2.bias", "image_encoder.trunk.blocks.7.mlp.layers.0.weight", "image_encoder.trunk.blocks.7.mlp.layers.0.bias", "image_encoder.trunk.blocks.7.mlp.layers.1.weight", "image_encoder.trunk.blocks.7.mlp.layers.1.bias", "image_encoder.trunk.blocks.8.norm1.weight", "image_encoder.trunk.blocks.8.norm1.bias", "image_encoder.trunk.blocks.8.attn.qkv.weight", "image_encoder.trunk.blocks.8.attn.qkv.bias", "image_encoder.trunk.blocks.8.attn.proj.weight", "image_encoder.trunk.blocks.8.attn.proj.bias", "image_encoder.trunk.blocks.8.norm2.weight", "image_encoder.trunk.blocks.8.norm2.bias", "image_encoder.trunk.blocks.8.mlp.layers.0.weight", "image_encoder.trunk.blocks.8.mlp.layers.0.bias", "image_encoder.trunk.blocks.8.mlp.layers.1.weight", "image_encoder.trunk.blocks.8.mlp.layers.1.bias", "image_encoder.trunk.blocks.9.norm1.weight", "image_encoder.trunk.blocks.9.norm1.bias", "image_encoder.trunk.blocks.9.attn.qkv.weight", "image_encoder.trunk.blocks.9.attn.qkv.bias", "image_encoder.trunk.blocks.9.attn.proj.weight", "image_encoder.trunk.blocks.9.attn.proj.bias", "image_encoder.trunk.blocks.9.norm2.weight", "image_encoder.trunk.blocks.9.norm2.bias", "image_encoder.trunk.blocks.9.mlp.layers.0.weight", "image_encoder.trunk.blocks.9.mlp.layers.0.bias", "image_encoder.trunk.blocks.9.mlp.layers.1.weight", "image_encoder.trunk.blocks.9.mlp.layers.1.bias", "image_encoder.trunk.blocks.10.norm1.weight", "image_encoder.trunk.blocks.10.norm1.bias", "image_encoder.trunk.blocks.10.attn.qkv.weight", "image_encoder.trunk.blocks.10.attn.qkv.bias", "image_encoder.trunk.blocks.10.attn.proj.weight", "image_encoder.trunk.blocks.10.attn.proj.bias", "image_encoder.trunk.blocks.10.norm2.weight", "image_encoder.trunk.blocks.10.norm2.bias", "image_encoder.trunk.blocks.10.mlp.layers.0.weight", "image_encoder.trunk.blocks.10.mlp.layers.0.bias", "image_encoder.trunk.blocks.10.mlp.layers.1.weight", "image_encoder.trunk.blocks.10.mlp.layers.1.bias", "image_encoder.trunk.blocks.11.norm1.weight", "image_encoder.trunk.blocks.11.norm1.bias", "image_encoder.trunk.blocks.11.attn.qkv.weight", "image_encoder.trunk.blocks.11.attn.qkv.bias", "image_encoder.trunk.blocks.11.attn.proj.weight", "image_encoder.trunk.blocks.11.attn.proj.bias", "image_encoder.trunk.blocks.11.norm2.weight", "image_encoder.trunk.blocks.11.norm2.bias", "image_encoder.trunk.blocks.11.mlp.layers.0.weight", "image_encoder.trunk.blocks.11.mlp.layers.0.bias", "image_encoder.trunk.blocks.11.mlp.layers.1.weight", "image_encoder.trunk.blocks.11.mlp.layers.1.bias", "image_encoder.trunk.blocks.12.norm1.weight", "image_encoder.trunk.blocks.12.norm1.bias", "image_encoder.trunk.blocks.12.attn.qkv.weight", "image_encoder.trunk.blocks.12.attn.qkv.bias", "image_encoder.trunk.blocks.12.attn.proj.weight", "image_encoder.trunk.blocks.12.attn.proj.bias", "image_encoder.trunk.blocks.12.norm2.weight", "image_encoder.trunk.blocks.12.norm2.bias", "image_encoder.trunk.blocks.12.mlp.layers.0.weight", "image_encoder.trunk.blocks.12.mlp.layers.0.bias", "image_encoder.trunk.blocks.12.mlp.layers.1.weight", "image_encoder.trunk.blocks.12.mlp.layers.1.bias", "image_encoder.trunk.blocks.13.norm1.weight", "image_encoder.trunk.blocks.13.norm1.bias", "image_encoder.trunk.blocks.13.attn.qkv.weight", "image_encoder.trunk.blocks.13.attn.qkv.bias", "image_encoder.trunk.blocks.13.attn.proj.weight", "image_encoder.trunk.blocks.13.attn.proj.bias", "image_encoder.trunk.blocks.13.norm2.weight", "image_encoder.trunk.blocks.13.norm2.bias", "image_encoder.trunk.blocks.13.mlp.layers.0.weight", "image_encoder.trunk.blocks.13.mlp.layers.0.bias", "image_encoder.trunk.blocks.13.mlp.layers.1.weight", "image_encoder.trunk.blocks.13.mlp.layers.1.bias", "image_encoder.trunk.blocks.14.norm1.weight", "image_encoder.trunk.blocks.14.norm1.bias", "image_encoder.trunk.blocks.14.attn.qkv.weight", "image_encoder.trunk.blocks.14.attn.qkv.bias", "image_encoder.trunk.blocks.14.attn.proj.weight", "image_encoder.trunk.blocks.14.attn.proj.bias", "image_encoder.trunk.blocks.14.norm2.weight", "image_encoder.trunk.blocks.14.norm2.bias", "image_encoder.trunk.blocks.14.mlp.layers.0.weight", "image_encoder.trunk.blocks.14.mlp.layers.0.bias", "image_encoder.trunk.blocks.14.mlp.layers.1.weight", "image_encoder.trunk.blocks.14.mlp.layers.1.bias", "image_encoder.trunk.blocks.15.norm1.weight", "image_encoder.trunk.blocks.15.norm1.bias", "image_encoder.trunk.blocks.15.attn.qkv.weight", "image_encoder.trunk.blocks.15.attn.qkv.bias", "image_encoder.trunk.blocks.15.attn.proj.weight", "image_encoder.trunk.blocks.15.attn.proj.bias", "image_encoder.trunk.blocks.15.norm2.weight", "image_encoder.trunk.blocks.15.norm2.bias", "image_encoder.trunk.blocks.15.mlp.layers.0.weight", "image_encoder.trunk.blocks.15.mlp.layers.0.bias", "image_encoder.trunk.blocks.15.mlp.layers.1.weight", "image_encoder.trunk.blocks.15.mlp.layers.1.bias", "image_encoder.trunk.blocks.16.norm1.weight", "image_encoder.trunk.blocks.16.norm1.bias", "image_encoder.trunk.blocks.16.attn.qkv.weight", "image_encoder.trunk.blocks.16.attn.qkv.bias", "image_encoder.trunk.blocks.16.attn.proj.weight", "image_encoder.trunk.blocks.16.attn.proj.bias", "image_encoder.trunk.blocks.16.norm2.weight", "image_encoder.trunk.blocks.16.norm2.bias", "image_encoder.trunk.blocks.16.mlp.layers.0.weight", "image_encoder.trunk.blocks.16.mlp.layers.0.bias", "image_encoder.trunk.blocks.16.mlp.layers.1.weight", "image_encoder.trunk.blocks.16.mlp.layers.1.bias", "image_encoder.trunk.blocks.17.norm1.weight", "image_encoder.trunk.blocks.17.norm1.bias", "image_encoder.trunk.blocks.17.attn.qkv.weight", "image_encoder.trunk.blocks.17.attn.qkv.bias", "image_encoder.trunk.blocks.17.attn.proj.weight", "image_encoder.trunk.blocks.17.attn.proj.bias", "image_encoder.trunk.blocks.17.norm2.weight", "image_encoder.trunk.blocks.17.norm2.bias", "image_encoder.trunk.blocks.17.mlp.layers.0.weight", "image_encoder.trunk.blocks.17.mlp.layers.0.bias", "image_encoder.trunk.blocks.17.mlp.layers.1.weight", "image_encoder.trunk.blocks.17.mlp.layers.1.bias", "image_encoder.trunk.blocks.18.norm1.weight", "image_encoder.trunk.blocks.18.norm1.bias", "image_encoder.trunk.blocks.18.attn.qkv.weight", "image_encoder.trunk.blocks.18.attn.qkv.bias", "image_encoder.trunk.blocks.18.attn.proj.weight", "image_encoder.trunk.blocks.18.attn.proj.bias", "image_encoder.trunk.blocks.18.norm2.weight", "image_encoder.trunk.blocks.18.norm2.bias", "image_encoder.trunk.blocks.18.mlp.layers.0.weight", "image_encoder.trunk.blocks.18.mlp.layers.0.bias", "image_encoder.trunk.blocks.18.mlp.layers.1.weight", "image_encoder.trunk.blocks.18.mlp.layers.1.bias", "image_encoder.trunk.blocks.19.norm1.weight", "image_encoder.trunk.blocks.19.norm1.bias", "image_encoder.trunk.blocks.19.attn.qkv.weight", "image_encoder.trunk.blocks.19.attn.qkv.bias", "image_encoder.trunk.blocks.19.attn.proj.weight", "image_encoder.trunk.blocks.19.attn.proj.bias", "image_encoder.trunk.blocks.19.norm2.weight", "image_encoder.trunk.blocks.19.norm2.bias", "image_encoder.trunk.blocks.19.mlp.layers.0.weight", "image_encoder.trunk.blocks.19.mlp.layers.0.bias", "image_encoder.trunk.blocks.19.mlp.layers.1.weight", "image_encoder.trunk.blocks.19.mlp.layers.1.bias", "image_encoder.trunk.blocks.20.norm1.weight", "image_encoder.trunk.blocks.20.norm1.bias", "image_encoder.trunk.blocks.20.attn.qkv.weight", "image_encoder.trunk.blocks.20.attn.qkv.bias", "image_encoder.trunk.blocks.20.attn.proj.weight", "image_encoder.trunk.blocks.20.attn.proj.bias", "image_encoder.trunk.blocks.20.norm2.weight", "image_encoder.trunk.blocks.20.norm2.bias", "image_encoder.trunk.blocks.20.mlp.layers.0.weight", "image_encoder.trunk.blocks.20.mlp.layers.0.bias", "image_encoder.trunk.blocks.20.mlp.layers.1.weight", "image_encoder.trunk.blocks.20.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.norm1.weight", "image_encoder.trunk.blocks.21.norm1.bias", "image_encoder.trunk.blocks.21.attn.qkv.weight", "image_encoder.trunk.blocks.21.attn.qkv.bias", "image_encoder.trunk.blocks.21.attn.proj.weight", "image_encoder.trunk.blocks.21.attn.proj.bias", "image_encoder.trunk.blocks.21.norm2.weight", "image_encoder.trunk.blocks.21.norm2.bias", "image_encoder.trunk.blocks.21.mlp.layers.0.weight", "image_encoder.trunk.blocks.21.mlp.layers.0.bias", "image_encoder.trunk.blocks.21.mlp.layers.1.weight", "image_encoder.trunk.blocks.21.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.proj.weight", "image_encoder.trunk.blocks.21.proj.bias", "image_encoder.trunk.blocks.22.norm1.weight", "image_encoder.trunk.blocks.22.norm1.bias", "image_encoder.trunk.blocks.22.attn.qkv.weight", "image_encoder.trunk.blocks.22.attn.qkv.bias", "image_encoder.trunk.blocks.22.attn.proj.weight", "image_encoder.trunk.blocks.22.attn.proj.bias", "image_encoder.trunk.blocks.22.norm2.weight", "image_encoder.trunk.blocks.22.norm2.bias", "image_encoder.trunk.blocks.22.mlp.layers.0.weight", "image_encoder.trunk.blocks.22.mlp.layers.0.bias", "image_encoder.trunk.blocks.22.mlp.layers.1.weight", "image_encoder.trunk.blocks.22.mlp.layers.1.bias", "image_encoder.trunk.blocks.23.norm1.weight", "image_encoder.trunk.blocks.23.norm1.bias", "image_encoder.trunk.blocks.23.attn.qkv.weight", "image_encoder.trunk.blocks.23.attn.qkv.bias", "image_encoder.trunk.blocks.23.attn.proj.weight", "image_encoder.trunk.blocks.23.attn.proj.bias", "image_encoder.trunk.blocks.23.norm2.weight", "image_encoder.trunk.blocks.23.norm2.bias", "image_encoder.trunk.blocks.23.mlp.layers.0.weight", "image_encoder.trunk.blocks.23.mlp.layers.0.bias", "image_encoder.trunk.blocks.23.mlp.layers.1.weight", "image_encoder.trunk.blocks.23.mlp.layers.1.bias", "image_encoder.neck.convs.0.conv.weight", "image_encoder.neck.convs.0.conv.bias", "image_encoder.neck.convs.1.conv.weight", "image_encoder.neck.convs.1.conv.bias", "image_encoder.neck.convs.2.conv.weight", "image_encoder.neck.convs.2.conv.bias", "image_encoder.neck.convs.3.conv.weight", "image_encoder.neck.convs.3.conv.bias", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "memory_encoder.mask_downsampler.encoder.0.weight", "memory_encoder.mask_downsampler.encoder.0.bias", "memory_encoder.mask_downsampler.encoder.1.weight", "memory_encoder.mask_downsampler.encoder.1.bias", "memory_encoder.mask_downsampler.encoder.3.weight", "memory_encoder.mask_downsampler.encoder.3.bias", "memory_encoder.mask_downsampler.encoder.4.weight", "memory_encoder.mask_downsampler.encoder.4.bias", "memory_encoder.mask_downsampler.encoder.6.weight", "memory_encoder.mask_downsampler.encoder.6.bias", "memory_encoder.mask_downsampler.encoder.7.weight", "memory_encoder.mask_downsampler.encoder.7.bias", "memory_encoder.mask_downsampler.encoder.9.weight", "memory_encoder.mask_downsampler.encoder.9.bias", "memory_encoder.mask_downsampler.encoder.10.weight", "memory_encoder.mask_downsampler.encoder.10.bias", "memory_encoder.mask_downsampler.encoder.12.weight", "memory_encoder.mask_downsampler.encoder.12.bias", "memory_encoder.pix_feat_proj.weight", "memory_encoder.pix_feat_proj.bias", "memory_encoder.fuser.layers.0.gamma", "memory_encoder.fuser.layers.0.dwconv.weight", "memory_encoder.fuser.layers.0.dwconv.bias", "memory_encoder.fuser.layers.0.norm.weight", "memory_encoder.fuser.layers.0.norm.bias", "memory_encoder.fuser.layers.0.pwconv1.weight", "memory_encoder.fuser.layers.0.pwconv1.bias", "memory_encoder.fuser.layers.0.pwconv2.weight", "memory_encoder.fuser.layers.0.pwconv2.bias", "memory_encoder.fuser.layers.1.gamma", "memory_encoder.fuser.layers.1.dwconv.weight", "memory_encoder.fuser.layers.1.dwconv.bias", "memory_encoder.fuser.layers.1.norm.weight", "memory_encoder.fuser.layers.1.norm.bias", "memory_encoder.fuser.layers.1.pwconv1.weight", "memory_encoder.fuser.layers.1.pwconv1.bias", "memory_encoder.fuser.layers.1.pwconv2.weight", "memory_encoder.fuser.layers.1.pwconv2.bias", "memory_encoder.out_proj.weight", "memory_encoder.out_proj.bias", "sam_prompt_encoder.pe_layer.positional_encoding_gaussian_matrix", "sam_prompt_encoder.point_embeddings.0.weight", "sam_prompt_encoder.point_embeddings.1.weight", "sam_prompt_encoder.point_embeddings.2.weight", "sam_prompt_encoder.point_embeddings.3.weight", "sam_prompt_encoder.not_a_point_embed.weight", "sam_prompt_encoder.mask_downscaling.0.weight", "sam_prompt_encoder.mask_downscaling.0.bias", "sam_prompt_encoder.mask_downscaling.1.weight", "sam_prompt_encoder.mask_downscaling.1.bias", "sam_prompt_encoder.mask_downscaling.3.weight", "sam_prompt_encoder.mask_downscaling.3.bias", "sam_prompt_encoder.mask_downscaling.4.weight", "sam_prompt_encoder.mask_downscaling.4.bias", "sam_prompt_encoder.mask_downscaling.6.weight", "sam_prompt_encoder.mask_downscaling.6.bias", "sam_prompt_encoder.no_mask_embed.weight", "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias", "sam_mask_decoder.transformer.layers.0.norm1.weight", "sam_mask_decoder.transformer.layers.0.norm1.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.layers.0.norm2.weight", "sam_mask_decoder.transformer.layers.0.norm2.bias", "sam_mask_decoder.transformer.layers.0.mlp.layers.0.weight", "sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias", "sam_mask_decoder.transformer.layers.0.mlp.layers.1.weight", "sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias", "sam_mask_decoder.transformer.layers.0.norm3.weight", "sam_mask_decoder.transformer.layers.0.norm3.bias", "sam_mask_decoder.transformer.layers.0.norm4.weight", "sam_mask_decoder.transformer.layers.0.norm4.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias", "sam_mask_decoder.transformer.layers.1.norm1.weight", "sam_mask_decoder.transformer.layers.1.norm1.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.layers.1.norm2.weight", "sam_mask_decoder.transformer.layers.1.norm2.bias", "sam_mask_decoder.transformer.layers.1.mlp.layers.0.weight", "sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias", "sam_mask_decoder.transformer.layers.1.mlp.layers.1.weight", "sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias", "sam_mask_decoder.transformer.layers.1.norm3.weight", "sam_mask_decoder.transformer.layers.1.norm3.bias", "sam_mask_decoder.transformer.layers.1.norm4.weight", "sam_mask_decoder.transformer.layers.1.norm4.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.norm_final_attn.weight", "sam_mask_decoder.transformer.norm_final_attn.bias", "sam_mask_decoder.iou_token.weight", "sam_mask_decoder.mask_tokens.weight", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.output_upscaling.0.weight", "sam_mask_decoder.output_upscaling.0.bias", "sam_mask_decoder.output_upscaling.1.weight", "sam_mask_decoder.output_upscaling.1.bias", "sam_mask_decoder.output_upscaling.3.weight", "sam_mask_decoder.output_upscaling.3.bias", "sam_mask_decoder.conv_s0.weight", "sam_mask_decoder.conv_s0.bias", "sam_mask_decoder.conv_s1.weight", "sam_mask_decoder.conv_s1.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias", "sam_mask_decoder.iou_prediction_head.layers.0.weight", "sam_mask_decoder.iou_prediction_head.layers.0.bias", "sam_mask_decoder.iou_prediction_head.layers.1.weight", "sam_mask_decoder.iou_prediction_head.layers.1.bias", "sam_mask_decoder.iou_prediction_head.layers.2.weight", "sam_mask_decoder.iou_prediction_head.layers.2.bias", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
	Unexpected key(s) in state_dict: "model", "optimizer", "epoch", "loss", "steps", "time_elapsed", "best_meter_values", "scaler". 
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3514, in load_model
    self.model = build_sam2(config_path, trained_model_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 167, in _load_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(sd)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3535, in load_model
    self.model.load_state_dict(checkpoint)
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "maskmem_tpos_enc", "no_mem_embed", "no_mem_pos_enc", "no_obj_ptr", "no_obj_embed_spatial", "image_encoder.trunk.pos_embed", "image_encoder.trunk.pos_embed_window", "image_encoder.trunk.patch_embed.proj.weight", "image_encoder.trunk.patch_embed.proj.bias", "image_encoder.trunk.blocks.0.norm1.weight", "image_encoder.trunk.blocks.0.norm1.bias", "image_encoder.trunk.blocks.0.attn.qkv.weight", "image_encoder.trunk.blocks.0.attn.qkv.bias", "image_encoder.trunk.blocks.0.attn.proj.weight", "image_encoder.trunk.blocks.0.attn.proj.bias", "image_encoder.trunk.blocks.0.norm2.weight", "image_encoder.trunk.blocks.0.norm2.bias", "image_encoder.trunk.blocks.0.mlp.layers.0.weight", "image_encoder.trunk.blocks.0.mlp.layers.0.bias", "image_encoder.trunk.blocks.0.mlp.layers.1.weight", "image_encoder.trunk.blocks.0.mlp.layers.1.bias", "image_encoder.trunk.blocks.1.norm1.weight", "image_encoder.trunk.blocks.1.norm1.bias", "image_encoder.trunk.blocks.1.attn.qkv.weight", "image_encoder.trunk.blocks.1.attn.qkv.bias", "image_encoder.trunk.blocks.1.attn.proj.weight", "image_encoder.trunk.blocks.1.attn.proj.bias", "image_encoder.trunk.blocks.1.norm2.weight", "image_encoder.trunk.blocks.1.norm2.bias", "image_encoder.trunk.blocks.1.mlp.layers.0.weight", "image_encoder.trunk.blocks.1.mlp.layers.0.bias", "image_encoder.trunk.blocks.1.mlp.layers.1.weight", "image_encoder.trunk.blocks.1.mlp.layers.1.bias", "image_encoder.trunk.blocks.2.norm1.weight", "image_encoder.trunk.blocks.2.norm1.bias", "image_encoder.trunk.blocks.2.attn.qkv.weight", "image_encoder.trunk.blocks.2.attn.qkv.bias", "image_encoder.trunk.blocks.2.attn.proj.weight", "image_encoder.trunk.blocks.2.attn.proj.bias", "image_encoder.trunk.blocks.2.norm2.weight", "image_encoder.trunk.blocks.2.norm2.bias", "image_encoder.trunk.blocks.2.mlp.layers.0.weight", "image_encoder.trunk.blocks.2.mlp.layers.0.bias", "image_encoder.trunk.blocks.2.mlp.layers.1.weight", "image_encoder.trunk.blocks.2.mlp.layers.1.bias", "image_encoder.trunk.blocks.2.proj.weight", "image_encoder.trunk.blocks.2.proj.bias", "image_encoder.trunk.blocks.3.norm1.weight", "image_encoder.trunk.blocks.3.norm1.bias", "image_encoder.trunk.blocks.3.attn.qkv.weight", "image_encoder.trunk.blocks.3.attn.qkv.bias", "image_encoder.trunk.blocks.3.attn.proj.weight", "image_encoder.trunk.blocks.3.attn.proj.bias", "image_encoder.trunk.blocks.3.norm2.weight", "image_encoder.trunk.blocks.3.norm2.bias", "image_encoder.trunk.blocks.3.mlp.layers.0.weight", "image_encoder.trunk.blocks.3.mlp.layers.0.bias", "image_encoder.trunk.blocks.3.mlp.layers.1.weight", "image_encoder.trunk.blocks.3.mlp.layers.1.bias", "image_encoder.trunk.blocks.4.norm1.weight", "image_encoder.trunk.blocks.4.norm1.bias", "image_encoder.trunk.blocks.4.attn.qkv.weight", "image_encoder.trunk.blocks.4.attn.qkv.bias", "image_encoder.trunk.blocks.4.attn.proj.weight", "image_encoder.trunk.blocks.4.attn.proj.bias", "image_encoder.trunk.blocks.4.norm2.weight", "image_encoder.trunk.blocks.4.norm2.bias", "image_encoder.trunk.blocks.4.mlp.layers.0.weight", "image_encoder.trunk.blocks.4.mlp.layers.0.bias", "image_encoder.trunk.blocks.4.mlp.layers.1.weight", "image_encoder.trunk.blocks.4.mlp.layers.1.bias", "image_encoder.trunk.blocks.5.norm1.weight", "image_encoder.trunk.blocks.5.norm1.bias", "image_encoder.trunk.blocks.5.attn.qkv.weight", "image_encoder.trunk.blocks.5.attn.qkv.bias", "image_encoder.trunk.blocks.5.attn.proj.weight", "image_encoder.trunk.blocks.5.attn.proj.bias", "image_encoder.trunk.blocks.5.norm2.weight", "image_encoder.trunk.blocks.5.norm2.bias", "image_encoder.trunk.blocks.5.mlp.layers.0.weight", "image_encoder.trunk.blocks.5.mlp.layers.0.bias", "image_encoder.trunk.blocks.5.mlp.layers.1.weight", "image_encoder.trunk.blocks.5.mlp.layers.1.bias", "image_encoder.trunk.blocks.5.proj.weight", "image_encoder.trunk.blocks.5.proj.bias", "image_encoder.trunk.blocks.6.norm1.weight", "image_encoder.trunk.blocks.6.norm1.bias", "image_encoder.trunk.blocks.6.attn.qkv.weight", "image_encoder.trunk.blocks.6.attn.qkv.bias", "image_encoder.trunk.blocks.6.attn.proj.weight", "image_encoder.trunk.blocks.6.attn.proj.bias", "image_encoder.trunk.blocks.6.norm2.weight", "image_encoder.trunk.blocks.6.norm2.bias", "image_encoder.trunk.blocks.6.mlp.layers.0.weight", "image_encoder.trunk.blocks.6.mlp.layers.0.bias", "image_encoder.trunk.blocks.6.mlp.layers.1.weight", "image_encoder.trunk.blocks.6.mlp.layers.1.bias", "image_encoder.trunk.blocks.7.norm1.weight", "image_encoder.trunk.blocks.7.norm1.bias", "image_encoder.trunk.blocks.7.attn.qkv.weight", "image_encoder.trunk.blocks.7.attn.qkv.bias", "image_encoder.trunk.blocks.7.attn.proj.weight", "image_encoder.trunk.blocks.7.attn.proj.bias", "image_encoder.trunk.blocks.7.norm2.weight", "image_encoder.trunk.blocks.7.norm2.bias", "image_encoder.trunk.blocks.7.mlp.layers.0.weight", "image_encoder.trunk.blocks.7.mlp.layers.0.bias", "image_encoder.trunk.blocks.7.mlp.layers.1.weight", "image_encoder.trunk.blocks.7.mlp.layers.1.bias", "image_encoder.trunk.blocks.8.norm1.weight", "image_encoder.trunk.blocks.8.norm1.bias", "image_encoder.trunk.blocks.8.attn.qkv.weight", "image_encoder.trunk.blocks.8.attn.qkv.bias", "image_encoder.trunk.blocks.8.attn.proj.weight", "image_encoder.trunk.blocks.8.attn.proj.bias", "image_encoder.trunk.blocks.8.norm2.weight", "image_encoder.trunk.blocks.8.norm2.bias", "image_encoder.trunk.blocks.8.mlp.layers.0.weight", "image_encoder.trunk.blocks.8.mlp.layers.0.bias", "image_encoder.trunk.blocks.8.mlp.layers.1.weight", "image_encoder.trunk.blocks.8.mlp.layers.1.bias", "image_encoder.trunk.blocks.9.norm1.weight", "image_encoder.trunk.blocks.9.norm1.bias", "image_encoder.trunk.blocks.9.attn.qkv.weight", "image_encoder.trunk.blocks.9.attn.qkv.bias", "image_encoder.trunk.blocks.9.attn.proj.weight", "image_encoder.trunk.blocks.9.attn.proj.bias", "image_encoder.trunk.blocks.9.norm2.weight", "image_encoder.trunk.blocks.9.norm2.bias", "image_encoder.trunk.blocks.9.mlp.layers.0.weight", "image_encoder.trunk.blocks.9.mlp.layers.0.bias", "image_encoder.trunk.blocks.9.mlp.layers.1.weight", "image_encoder.trunk.blocks.9.mlp.layers.1.bias", "image_encoder.trunk.blocks.10.norm1.weight", "image_encoder.trunk.blocks.10.norm1.bias", "image_encoder.trunk.blocks.10.attn.qkv.weight", "image_encoder.trunk.blocks.10.attn.qkv.bias", "image_encoder.trunk.blocks.10.attn.proj.weight", "image_encoder.trunk.blocks.10.attn.proj.bias", "image_encoder.trunk.blocks.10.norm2.weight", "image_encoder.trunk.blocks.10.norm2.bias", "image_encoder.trunk.blocks.10.mlp.layers.0.weight", "image_encoder.trunk.blocks.10.mlp.layers.0.bias", "image_encoder.trunk.blocks.10.mlp.layers.1.weight", "image_encoder.trunk.blocks.10.mlp.layers.1.bias", "image_encoder.trunk.blocks.11.norm1.weight", "image_encoder.trunk.blocks.11.norm1.bias", "image_encoder.trunk.blocks.11.attn.qkv.weight", "image_encoder.trunk.blocks.11.attn.qkv.bias", "image_encoder.trunk.blocks.11.attn.proj.weight", "image_encoder.trunk.blocks.11.attn.proj.bias", "image_encoder.trunk.blocks.11.norm2.weight", "image_encoder.trunk.blocks.11.norm2.bias", "image_encoder.trunk.blocks.11.mlp.layers.0.weight", "image_encoder.trunk.blocks.11.mlp.layers.0.bias", "image_encoder.trunk.blocks.11.mlp.layers.1.weight", "image_encoder.trunk.blocks.11.mlp.layers.1.bias", "image_encoder.trunk.blocks.12.norm1.weight", "image_encoder.trunk.blocks.12.norm1.bias", "image_encoder.trunk.blocks.12.attn.qkv.weight", "image_encoder.trunk.blocks.12.attn.qkv.bias", "image_encoder.trunk.blocks.12.attn.proj.weight", "image_encoder.trunk.blocks.12.attn.proj.bias", "image_encoder.trunk.blocks.12.norm2.weight", "image_encoder.trunk.blocks.12.norm2.bias", "image_encoder.trunk.blocks.12.mlp.layers.0.weight", "image_encoder.trunk.blocks.12.mlp.layers.0.bias", "image_encoder.trunk.blocks.12.mlp.layers.1.weight", "image_encoder.trunk.blocks.12.mlp.layers.1.bias", "image_encoder.trunk.blocks.13.norm1.weight", "image_encoder.trunk.blocks.13.norm1.bias", "image_encoder.trunk.blocks.13.attn.qkv.weight", "image_encoder.trunk.blocks.13.attn.qkv.bias", "image_encoder.trunk.blocks.13.attn.proj.weight", "image_encoder.trunk.blocks.13.attn.proj.bias", "image_encoder.trunk.blocks.13.norm2.weight", "image_encoder.trunk.blocks.13.norm2.bias", "image_encoder.trunk.blocks.13.mlp.layers.0.weight", "image_encoder.trunk.blocks.13.mlp.layers.0.bias", "image_encoder.trunk.blocks.13.mlp.layers.1.weight", "image_encoder.trunk.blocks.13.mlp.layers.1.bias", "image_encoder.trunk.blocks.14.norm1.weight", "image_encoder.trunk.blocks.14.norm1.bias", "image_encoder.trunk.blocks.14.attn.qkv.weight", "image_encoder.trunk.blocks.14.attn.qkv.bias", "image_encoder.trunk.blocks.14.attn.proj.weight", "image_encoder.trunk.blocks.14.attn.proj.bias", "image_encoder.trunk.blocks.14.norm2.weight", "image_encoder.trunk.blocks.14.norm2.bias", "image_encoder.trunk.blocks.14.mlp.layers.0.weight", "image_encoder.trunk.blocks.14.mlp.layers.0.bias", "image_encoder.trunk.blocks.14.mlp.layers.1.weight", "image_encoder.trunk.blocks.14.mlp.layers.1.bias", "image_encoder.trunk.blocks.15.norm1.weight", "image_encoder.trunk.blocks.15.norm1.bias", "image_encoder.trunk.blocks.15.attn.qkv.weight", "image_encoder.trunk.blocks.15.attn.qkv.bias", "image_encoder.trunk.blocks.15.attn.proj.weight", "image_encoder.trunk.blocks.15.attn.proj.bias", "image_encoder.trunk.blocks.15.norm2.weight", "image_encoder.trunk.blocks.15.norm2.bias", "image_encoder.trunk.blocks.15.mlp.layers.0.weight", "image_encoder.trunk.blocks.15.mlp.layers.0.bias", "image_encoder.trunk.blocks.15.mlp.layers.1.weight", "image_encoder.trunk.blocks.15.mlp.layers.1.bias", "image_encoder.trunk.blocks.16.norm1.weight", "image_encoder.trunk.blocks.16.norm1.bias", "image_encoder.trunk.blocks.16.attn.qkv.weight", "image_encoder.trunk.blocks.16.attn.qkv.bias", "image_encoder.trunk.blocks.16.attn.proj.weight", "image_encoder.trunk.blocks.16.attn.proj.bias", "image_encoder.trunk.blocks.16.norm2.weight", "image_encoder.trunk.blocks.16.norm2.bias", "image_encoder.trunk.blocks.16.mlp.layers.0.weight", "image_encoder.trunk.blocks.16.mlp.layers.0.bias", "image_encoder.trunk.blocks.16.mlp.layers.1.weight", "image_encoder.trunk.blocks.16.mlp.layers.1.bias", "image_encoder.trunk.blocks.17.norm1.weight", "image_encoder.trunk.blocks.17.norm1.bias", "image_encoder.trunk.blocks.17.attn.qkv.weight", "image_encoder.trunk.blocks.17.attn.qkv.bias", "image_encoder.trunk.blocks.17.attn.proj.weight", "image_encoder.trunk.blocks.17.attn.proj.bias", "image_encoder.trunk.blocks.17.norm2.weight", "image_encoder.trunk.blocks.17.norm2.bias", "image_encoder.trunk.blocks.17.mlp.layers.0.weight", "image_encoder.trunk.blocks.17.mlp.layers.0.bias", "image_encoder.trunk.blocks.17.mlp.layers.1.weight", "image_encoder.trunk.blocks.17.mlp.layers.1.bias", "image_encoder.trunk.blocks.18.norm1.weight", "image_encoder.trunk.blocks.18.norm1.bias", "image_encoder.trunk.blocks.18.attn.qkv.weight", "image_encoder.trunk.blocks.18.attn.qkv.bias", "image_encoder.trunk.blocks.18.attn.proj.weight", "image_encoder.trunk.blocks.18.attn.proj.bias", "image_encoder.trunk.blocks.18.norm2.weight", "image_encoder.trunk.blocks.18.norm2.bias", "image_encoder.trunk.blocks.18.mlp.layers.0.weight", "image_encoder.trunk.blocks.18.mlp.layers.0.bias", "image_encoder.trunk.blocks.18.mlp.layers.1.weight", "image_encoder.trunk.blocks.18.mlp.layers.1.bias", "image_encoder.trunk.blocks.19.norm1.weight", "image_encoder.trunk.blocks.19.norm1.bias", "image_encoder.trunk.blocks.19.attn.qkv.weight", "image_encoder.trunk.blocks.19.attn.qkv.bias", "image_encoder.trunk.blocks.19.attn.proj.weight", "image_encoder.trunk.blocks.19.attn.proj.bias", "image_encoder.trunk.blocks.19.norm2.weight", "image_encoder.trunk.blocks.19.norm2.bias", "image_encoder.trunk.blocks.19.mlp.layers.0.weight", "image_encoder.trunk.blocks.19.mlp.layers.0.bias", "image_encoder.trunk.blocks.19.mlp.layers.1.weight", "image_encoder.trunk.blocks.19.mlp.layers.1.bias", "image_encoder.trunk.blocks.20.norm1.weight", "image_encoder.trunk.blocks.20.norm1.bias", "image_encoder.trunk.blocks.20.attn.qkv.weight", "image_encoder.trunk.blocks.20.attn.qkv.bias", "image_encoder.trunk.blocks.20.attn.proj.weight", "image_encoder.trunk.blocks.20.attn.proj.bias", "image_encoder.trunk.blocks.20.norm2.weight", "image_encoder.trunk.blocks.20.norm2.bias", "image_encoder.trunk.blocks.20.mlp.layers.0.weight", "image_encoder.trunk.blocks.20.mlp.layers.0.bias", "image_encoder.trunk.blocks.20.mlp.layers.1.weight", "image_encoder.trunk.blocks.20.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.norm1.weight", "image_encoder.trunk.blocks.21.norm1.bias", "image_encoder.trunk.blocks.21.attn.qkv.weight", "image_encoder.trunk.blocks.21.attn.qkv.bias", "image_encoder.trunk.blocks.21.attn.proj.weight", "image_encoder.trunk.blocks.21.attn.proj.bias", "image_encoder.trunk.blocks.21.norm2.weight", "image_encoder.trunk.blocks.21.norm2.bias", "image_encoder.trunk.blocks.21.mlp.layers.0.weight", "image_encoder.trunk.blocks.21.mlp.layers.0.bias", "image_encoder.trunk.blocks.21.mlp.layers.1.weight", "image_encoder.trunk.blocks.21.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.proj.weight", "image_encoder.trunk.blocks.21.proj.bias", "image_encoder.trunk.blocks.22.norm1.weight", "image_encoder.trunk.blocks.22.norm1.bias", "image_encoder.trunk.blocks.22.attn.qkv.weight", "image_encoder.trunk.blocks.22.attn.qkv.bias", "image_encoder.trunk.blocks.22.attn.proj.weight", "image_encoder.trunk.blocks.22.attn.proj.bias", "image_encoder.trunk.blocks.22.norm2.weight", "image_encoder.trunk.blocks.22.norm2.bias", "image_encoder.trunk.blocks.22.mlp.layers.0.weight", "image_encoder.trunk.blocks.22.mlp.layers.0.bias", "image_encoder.trunk.blocks.22.mlp.layers.1.weight", "image_encoder.trunk.blocks.22.mlp.layers.1.bias", "image_encoder.trunk.blocks.23.norm1.weight", "image_encoder.trunk.blocks.23.norm1.bias", "image_encoder.trunk.blocks.23.attn.qkv.weight", "image_encoder.trunk.blocks.23.attn.qkv.bias", "image_encoder.trunk.blocks.23.attn.proj.weight", "image_encoder.trunk.blocks.23.attn.proj.bias", "image_encoder.trunk.blocks.23.norm2.weight", "image_encoder.trunk.blocks.23.norm2.bias", "image_encoder.trunk.blocks.23.mlp.layers.0.weight", "image_encoder.trunk.blocks.23.mlp.layers.0.bias", "image_encoder.trunk.blocks.23.mlp.layers.1.weight", "image_encoder.trunk.blocks.23.mlp.layers.1.bias", "image_encoder.neck.convs.0.conv.weight", "image_encoder.neck.convs.0.conv.bias", "image_encoder.neck.convs.1.conv.weight", "image_encoder.neck.convs.1.conv.bias", "image_encoder.neck.convs.2.conv.weight", "image_encoder.neck.convs.2.conv.bias", "image_encoder.neck.convs.3.conv.weight", "image_encoder.neck.convs.3.conv.bias", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "memory_encoder.mask_downsampler.encoder.0.weight", "memory_encoder.mask_downsampler.encoder.0.bias", "memory_encoder.mask_downsampler.encoder.1.weight", "memory_encoder.mask_downsampler.encoder.1.bias", "memory_encoder.mask_downsampler.encoder.3.weight", "memory_encoder.mask_downsampler.encoder.3.bias", "memory_encoder.mask_downsampler.encoder.4.weight", "memory_encoder.mask_downsampler.encoder.4.bias", "memory_encoder.mask_downsampler.encoder.6.weight", "memory_encoder.mask_downsampler.encoder.6.bias", "memory_encoder.mask_downsampler.encoder.7.weight", "memory_encoder.mask_downsampler.encoder.7.bias", "memory_encoder.mask_downsampler.encoder.9.weight", "memory_encoder.mask_downsampler.encoder.9.bias", "memory_encoder.mask_downsampler.encoder.10.weight", "memory_encoder.mask_downsampler.encoder.10.bias", "memory_encoder.mask_downsampler.encoder.12.weight", "memory_encoder.mask_downsampler.encoder.12.bias", "memory_encoder.pix_feat_proj.weight", "memory_encoder.pix_feat_proj.bias", "memory_encoder.fuser.layers.0.gamma", "memory_encoder.fuser.layers.0.dwconv.weight", "memory_encoder.fuser.layers.0.dwconv.bias", "memory_encoder.fuser.layers.0.norm.weight", "memory_encoder.fuser.layers.0.norm.bias", "memory_encoder.fuser.layers.0.pwconv1.weight", "memory_encoder.fuser.layers.0.pwconv1.bias", "memory_encoder.fuser.layers.0.pwconv2.weight", "memory_encoder.fuser.layers.0.pwconv2.bias", "memory_encoder.fuser.layers.1.gamma", "memory_encoder.fuser.layers.1.dwconv.weight", "memory_encoder.fuser.layers.1.dwconv.bias", "memory_encoder.fuser.layers.1.norm.weight", "memory_encoder.fuser.layers.1.norm.bias", "memory_encoder.fuser.layers.1.pwconv1.weight", "memory_encoder.fuser.layers.1.pwconv1.bias", "memory_encoder.fuser.layers.1.pwconv2.weight", "memory_encoder.fuser.layers.1.pwconv2.bias", "memory_encoder.out_proj.weight", "memory_encoder.out_proj.bias", "sam_prompt_encoder.pe_layer.positional_encoding_gaussian_matrix", "sam_prompt_encoder.point_embeddings.0.weight", "sam_prompt_encoder.point_embeddings.1.weight", "sam_prompt_encoder.point_embeddings.2.weight", "sam_prompt_encoder.point_embeddings.3.weight", "sam_prompt_encoder.not_a_point_embed.weight", "sam_prompt_encoder.mask_downscaling.0.weight", "sam_prompt_encoder.mask_downscaling.0.bias", "sam_prompt_encoder.mask_downscaling.1.weight", "sam_prompt_encoder.mask_downscaling.1.bias", "sam_prompt_encoder.mask_downscaling.3.weight", "sam_prompt_encoder.mask_downscaling.3.bias", "sam_prompt_encoder.mask_downscaling.4.weight", "sam_prompt_encoder.mask_downscaling.4.bias", "sam_prompt_encoder.mask_downscaling.6.weight", "sam_prompt_encoder.mask_downscaling.6.bias", "sam_prompt_encoder.no_mask_embed.weight", "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.q_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.k_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.v_proj.bias", "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.weight", "sam_mask_decoder.transformer.layers.0.self_attn.out_proj.bias", "sam_mask_decoder.transformer.layers.0.norm1.weight", "sam_mask_decoder.transformer.layers.0.norm1.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.layers.0.norm2.weight", "sam_mask_decoder.transformer.layers.0.norm2.bias", "sam_mask_decoder.transformer.layers.0.mlp.layers.0.weight", "sam_mask_decoder.transformer.layers.0.mlp.layers.0.bias", "sam_mask_decoder.transformer.layers.0.mlp.layers.1.weight", "sam_mask_decoder.transformer.layers.0.mlp.layers.1.bias", "sam_mask_decoder.transformer.layers.0.norm3.weight", "sam_mask_decoder.transformer.layers.0.norm3.bias", "sam_mask_decoder.transformer.layers.0.norm4.weight", "sam_mask_decoder.transformer.layers.0.norm4.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.q_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.k_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.v_proj.bias", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.weight", "sam_mask_decoder.transformer.layers.0.cross_attn_image_to_token.out_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.q_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.k_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.v_proj.bias", "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.weight", "sam_mask_decoder.transformer.layers.1.self_attn.out_proj.bias", "sam_mask_decoder.transformer.layers.1.norm1.weight", "sam_mask_decoder.transformer.layers.1.norm1.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.layers.1.norm2.weight", "sam_mask_decoder.transformer.layers.1.norm2.bias", "sam_mask_decoder.transformer.layers.1.mlp.layers.0.weight", "sam_mask_decoder.transformer.layers.1.mlp.layers.0.bias", "sam_mask_decoder.transformer.layers.1.mlp.layers.1.weight", "sam_mask_decoder.transformer.layers.1.mlp.layers.1.bias", "sam_mask_decoder.transformer.layers.1.norm3.weight", "sam_mask_decoder.transformer.layers.1.norm3.bias", "sam_mask_decoder.transformer.layers.1.norm4.weight", "sam_mask_decoder.transformer.layers.1.norm4.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.q_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.k_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.v_proj.bias", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.weight", "sam_mask_decoder.transformer.layers.1.cross_attn_image_to_token.out_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.q_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.k_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.v_proj.bias", "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.weight", "sam_mask_decoder.transformer.final_attn_token_to_image.out_proj.bias", "sam_mask_decoder.transformer.norm_final_attn.weight", "sam_mask_decoder.transformer.norm_final_attn.bias", "sam_mask_decoder.iou_token.weight", "sam_mask_decoder.mask_tokens.weight", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.output_upscaling.0.weight", "sam_mask_decoder.output_upscaling.0.bias", "sam_mask_decoder.output_upscaling.1.weight", "sam_mask_decoder.output_upscaling.1.bias", "sam_mask_decoder.output_upscaling.3.weight", "sam_mask_decoder.output_upscaling.3.bias", "sam_mask_decoder.conv_s0.weight", "sam_mask_decoder.conv_s0.bias", "sam_mask_decoder.conv_s1.weight", "sam_mask_decoder.conv_s1.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.0.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.1.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.2.layers.2.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.0.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.1.bias", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.weight", "sam_mask_decoder.output_hypernetworks_mlps.3.layers.2.bias", "sam_mask_decoder.iou_prediction_head.layers.0.weight", "sam_mask_decoder.iou_prediction_head.layers.0.bias", "sam_mask_decoder.iou_prediction_head.layers.1.weight", "sam_mask_decoder.iou_prediction_head.layers.1.bias", "sam_mask_decoder.iou_prediction_head.layers.2.weight", "sam_mask_decoder.iou_prediction_head.layers.2.bias", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
	Unexpected key(s) in state_dict: "model", "optimizer", "epoch", "loss", "steps", "time_elapsed", "best_meter_values", "scaler". 
2025-11-27 14:27:03,619 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:27:03,738 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:27:11,386 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:27:11,994 - __main__ - ERROR - 加载模型出错: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3514, in load_model
    self.model = build_sam2(config_path, trained_model_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 167, in _load_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(sd)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3538, in load_model
    self.model.load_state_dict(model_weights)
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
2025-11-27 14:28:29,834 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:28:29,990 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:28:38,075 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:28:38,816 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 14:28:38,980 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:28:38,980 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 14:28:49,555 - __main__ - INFO - 开始加载图像
2025-11-27 14:29:22,865 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:29:23,000 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:29:31,429 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:29:32,041 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 14:29:32,157 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:29:32,157 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 14:29:33,723 - __main__ - INFO - 开始加载图像
2025-11-27 14:29:38,088 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:29:38,089 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_0-44.bmp, 保留视图状态: False
2025-11-27 14:29:38,089 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:29:38,089 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:29:38,098 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 14:29:38,098 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 14:29:38,098 - __main__ - INFO - 图像设置完成
2025-11-27 14:29:38,099 - __main__ - INFO - 已加载图像: 1_0-44.bmp
2025-11-27 14:29:38,101 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 14:29:38,101 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:29:38,101 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 14:29:38,101 - __main__ - INFO - 调用predictor.set_image
2025-11-27 14:29:38,101 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 14:29:38,238 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 14:29:38,913 - root - INFO - Image embeddings computed.
2025-11-27 14:29:38,913 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 14:30:07,946 - __main__ - INFO - 开始加载图像
2025-11-27 14:30:15,328 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 14:30:15,328 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp, 保留视图状态: False
2025-11-27 14:30:15,329 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 14:30:15,329 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 14:30:15,330 - __main__ - INFO - 图像加载成功，尺寸: 400x400
2025-11-27 14:30:15,330 - __main__ - INFO - 图像缩放比例: 0.795, 视图大小: 689x318, 图像大小: 400x400
2025-11-27 14:30:15,330 - __main__ - INFO - 图像设置完成
2025-11-27 14:30:15,330 - __main__ - INFO - 已加载图像: 1_1-3999998888687 (27).bmp
2025-11-27 14:30:15,331 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (400, 400, 3)
2025-11-27 14:30:15,331 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:30:15,331 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 14:30:15,332 - __main__ - INFO - 调用predictor.set_image
2025-11-27 14:30:15,332 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 14:30:15,359 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 14:30:15,372 - root - INFO - Image embeddings computed.
2025-11-27 14:30:15,372 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 14:30:25,906 - __main__ - INFO - 开始加载目标图像
2025-11-27 14:30:27,121 - __main__ - INFO - 用户取消了目标图像选择
2025-11-27 14:30:28,267 - __main__ - INFO - 开始加载图像
2025-11-27 14:30:29,316 - __main__ - INFO - 用户取消了图像选择
2025-11-27 14:30:30,515 - __main__ - INFO - 开始加载图像
2025-11-27 14:30:40,104 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/173608179-28.bmp
2025-11-27 14:30:40,104 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/173608179-28.bmp, 保留视图状态: False
2025-11-27 14:30:40,104 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/173608179-28.bmp
2025-11-27 14:30:40,104 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/173608179-28.bmp
2025-11-27 14:30:40,106 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 14:30:40,106 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 14:30:40,106 - __main__ - INFO - 图像设置完成
2025-11-27 14:30:40,106 - __main__ - INFO - 已加载图像: 173608179-28.bmp
2025-11-27 14:30:40,108 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 14:30:40,108 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:30:40,108 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 14:30:40,108 - __main__ - INFO - 调用predictor.set_image
2025-11-27 14:30:40,108 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 14:30:40,121 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 14:30:40,135 - root - INFO - Image embeddings computed.
2025-11-27 14:30:40,136 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 14:37:16,823 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:37:16,986 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:37:25,053 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:37:25,780 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 14:37:25,910 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:37:25,910 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 14:37:32,971 - __main__ - INFO - 开始加载图像
2025-11-27 14:37:40,328 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:37:40,328 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_0-44.bmp, 保留视图状态: False
2025-11-27 14:37:40,329 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:37:40,329 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_0-44.bmp
2025-11-27 14:37:40,337 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 14:37:40,338 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 14:37:40,338 - __main__ - INFO - 图像设置完成
2025-11-27 14:37:40,338 - __main__ - INFO - 已加载图像: 1_0-44.bmp
2025-11-27 14:37:40,340 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 14:37:40,340 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:37:40,340 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 14:37:40,340 - __main__ - INFO - 调用predictor.set_image
2025-11-27 14:37:40,341 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 14:37:40,452 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 14:37:40,934 - root - INFO - Image embeddings computed.
2025-11-27 14:37:40,934 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 14:38:29,930 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:38:30,081 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:38:38,692 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:38:39,773 - __main__ - ERROR - 加载模型出错: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3533, in load_model
    self.model.load_state_dict(model_weights, strict=True)
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
2025-11-27 14:47:51,986 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:47:52,148 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:48:01,702 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:48:02,401 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 14:48:02,528 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:48:02,528 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 14:50:01,089 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:50:01,215 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:50:14,310 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:50:15,060 - __main__ - ERROR - 加载模型出错: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3532, in load_model
    self.model = build_sam2(config_path, temp_ckpt_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 167, in _load_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(sd)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3556, in load_model
    self.model.load_state_dict(model_weights, strict=True)
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
2025-11-27 14:50:28,680 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:50:29,124 - __main__ - ERROR - 加载模型出错: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3532, in load_model
    self.model = build_sam2(config_path, temp_ckpt_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 167, in _load_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(sd)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3556, in load_model
    self.model.load_state_dict(model_weights, strict=True)
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
2025-11-27 14:53:47,492 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 14:53:47,649 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 14:53:58,131 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 14:53:58,903 - __main__ - WARNING - 模型加载时缺失键: ['no_obj_ptr', 'no_obj_embed_spatial', 'mask_downsample.weight', 'mask_downsample.bias', 'memory_attention.layers.0.self_attn.q_proj.weight', 'memory_attention.layers.0.self_attn.q_proj.bias', 'memory_attention.layers.0.self_attn.k_proj.weight', 'memory_attention.layers.0.self_attn.k_proj.bias', 'memory_attention.layers.0.self_attn.v_proj.weight', 'memory_attention.layers.0.self_attn.v_proj.bias', 'memory_attention.layers.0.self_attn.out_proj.weight', 'memory_attention.layers.0.self_attn.out_proj.bias', 'memory_attention.layers.0.cross_attn_image.q_proj.weight', 'memory_attention.layers.0.cross_attn_image.q_proj.bias', 'memory_attention.layers.0.cross_attn_image.k_proj.weight', 'memory_attention.layers.0.cross_attn_image.k_proj.bias', 'memory_attention.layers.0.cross_attn_image.v_proj.weight', 'memory_attention.layers.0.cross_attn_image.v_proj.bias', 'memory_attention.layers.0.cross_attn_image.out_proj.weight', 'memory_attention.layers.0.cross_attn_image.out_proj.bias', 'memory_attention.layers.0.linear1.weight', 'memory_attention.layers.0.linear1.bias', 'memory_attention.layers.0.linear2.weight', 'memory_attention.layers.0.linear2.bias', 'memory_attention.layers.0.norm1.weight', 'memory_attention.layers.0.norm1.bias', 'memory_attention.layers.0.norm2.weight', 'memory_attention.layers.0.norm2.bias', 'memory_attention.layers.0.norm3.weight', 'memory_attention.layers.0.norm3.bias', 'memory_attention.layers.1.self_attn.q_proj.weight', 'memory_attention.layers.1.self_attn.q_proj.bias', 'memory_attention.layers.1.self_attn.k_proj.weight', 'memory_attention.layers.1.self_attn.k_proj.bias', 'memory_attention.layers.1.self_attn.v_proj.weight', 'memory_attention.layers.1.self_attn.v_proj.bias', 'memory_attention.layers.1.self_attn.out_proj.weight', 'memory_attention.layers.1.self_attn.out_proj.bias', 'memory_attention.layers.1.cross_attn_image.q_proj.weight', 'memory_attention.layers.1.cross_attn_image.q_proj.bias', 'memory_attention.layers.1.cross_attn_image.k_proj.weight', 'memory_attention.layers.1.cross_attn_image.k_proj.bias', 'memory_attention.layers.1.cross_attn_image.v_proj.weight', 'memory_attention.layers.1.cross_attn_image.v_proj.bias', 'memory_attention.layers.1.cross_attn_image.out_proj.weight', 'memory_attention.layers.1.cross_attn_image.out_proj.bias', 'memory_attention.layers.1.linear1.weight', 'memory_attention.layers.1.linear1.bias', 'memory_attention.layers.1.linear2.weight', 'memory_attention.layers.1.linear2.bias', 'memory_attention.layers.1.norm1.weight', 'memory_attention.layers.1.norm1.bias', 'memory_attention.layers.1.norm2.weight', 'memory_attention.layers.1.norm2.bias', 'memory_attention.layers.1.norm3.weight', 'memory_attention.layers.1.norm3.bias', 'memory_attention.layers.2.self_attn.q_proj.weight', 'memory_attention.layers.2.self_attn.q_proj.bias', 'memory_attention.layers.2.self_attn.k_proj.weight', 'memory_attention.layers.2.self_attn.k_proj.bias', 'memory_attention.layers.2.self_attn.v_proj.weight', 'memory_attention.layers.2.self_attn.v_proj.bias', 'memory_attention.layers.2.self_attn.out_proj.weight', 'memory_attention.layers.2.self_attn.out_proj.bias', 'memory_attention.layers.2.cross_attn_image.q_proj.weight', 'memory_attention.layers.2.cross_attn_image.q_proj.bias', 'memory_attention.layers.2.cross_attn_image.k_proj.weight', 'memory_attention.layers.2.cross_attn_image.k_proj.bias', 'memory_attention.layers.2.cross_attn_image.v_proj.weight', 'memory_attention.layers.2.cross_attn_image.v_proj.bias', 'memory_attention.layers.2.cross_attn_image.out_proj.weight', 'memory_attention.layers.2.cross_attn_image.out_proj.bias', 'memory_attention.layers.2.linear1.weight', 'memory_attention.layers.2.linear1.bias', 'memory_attention.layers.2.linear2.weight', 'memory_attention.layers.2.linear2.bias', 'memory_attention.layers.2.norm1.weight', 'memory_attention.layers.2.norm1.bias', 'memory_attention.layers.2.norm2.weight', 'memory_attention.layers.2.norm2.bias', 'memory_attention.layers.2.norm3.weight', 'memory_attention.layers.2.norm3.bias', 'memory_attention.layers.3.self_attn.q_proj.weight', 'memory_attention.layers.3.self_attn.q_proj.bias', 'memory_attention.layers.3.self_attn.k_proj.weight', 'memory_attention.layers.3.self_attn.k_proj.bias', 'memory_attention.layers.3.self_attn.v_proj.weight', 'memory_attention.layers.3.self_attn.v_proj.bias', 'memory_attention.layers.3.self_attn.out_proj.weight', 'memory_attention.layers.3.self_attn.out_proj.bias', 'memory_attention.layers.3.cross_attn_image.q_proj.weight', 'memory_attention.layers.3.cross_attn_image.q_proj.bias', 'memory_attention.layers.3.cross_attn_image.k_proj.weight', 'memory_attention.layers.3.cross_attn_image.k_proj.bias', 'memory_attention.layers.3.cross_attn_image.v_proj.weight', 'memory_attention.layers.3.cross_attn_image.v_proj.bias', 'memory_attention.layers.3.cross_attn_image.out_proj.weight', 'memory_attention.layers.3.cross_attn_image.out_proj.bias', 'memory_attention.layers.3.linear1.weight', 'memory_attention.layers.3.linear1.bias', 'memory_attention.layers.3.linear2.weight', 'memory_attention.layers.3.linear2.bias', 'memory_attention.layers.3.norm1.weight', 'memory_attention.layers.3.norm1.bias', 'memory_attention.layers.3.norm2.weight', 'memory_attention.layers.3.norm2.bias', 'memory_attention.layers.3.norm3.weight', 'memory_attention.layers.3.norm3.bias', 'memory_attention.norm.weight', 'memory_attention.norm.bias', 'sam_mask_decoder.obj_score_token.weight', 'sam_mask_decoder.pred_obj_score_head.layers.0.weight', 'sam_mask_decoder.pred_obj_score_head.layers.0.bias', 'sam_mask_decoder.pred_obj_score_head.layers.1.weight', 'sam_mask_decoder.pred_obj_score_head.layers.1.bias', 'sam_mask_decoder.pred_obj_score_head.layers.2.weight', 'sam_mask_decoder.pred_obj_score_head.layers.2.bias', 'obj_ptr_proj.layers.0.weight', 'obj_ptr_proj.layers.0.bias', 'obj_ptr_proj.layers.1.weight', 'obj_ptr_proj.layers.1.bias', 'obj_ptr_proj.layers.2.weight', 'obj_ptr_proj.layers.2.bias', 'obj_ptr_tpos_proj.weight', 'obj_ptr_tpos_proj.bias']
2025-11-27 14:53:58,906 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 14:53:59,045 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:53:59,045 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 14:54:21,043 - __main__ - INFO - 开始加载图像
2025-11-27 14:54:26,913 - __main__ - INFO - 用户取消了图像选择
2025-11-27 14:54:28,467 - __main__ - INFO - 开始加载图像
2025-11-27 14:54:34,607 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-125.bmp
2025-11-27 14:54:34,607 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-125.bmp, 保留视图状态: False
2025-11-27 14:54:34,607 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-125.bmp
2025-11-27 14:54:34,607 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-125.bmp
2025-11-27 14:54:34,632 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 14:54:34,633 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 14:54:34,633 - __main__ - INFO - 图像设置完成
2025-11-27 14:54:34,633 - __main__ - INFO - 已加载图像: 1_1-125.bmp
2025-11-27 14:54:34,635 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 14:54:34,635 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 14:54:34,635 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 14:54:34,635 - __main__ - INFO - 调用predictor.set_image
2025-11-27 14:54:34,635 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 14:54:34,808 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 14:54:35,371 - root - INFO - Image embeddings computed.
2025-11-27 14:54:35,371 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:03:28,056 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 15:03:28,216 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 15:03:39,531 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 15:03:40,680 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 15:03:40,906 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:03:40,906 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 15:04:37,524 - __main__ - INFO - 启动SAM2应用程序
2025-11-27 15:04:37,649 - __main__ - INFO - 应用程序窗口已显示
2025-11-27 15:04:52,003 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 15:04:52,594 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 15:04:52,710 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:04:52,710 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 15:04:58,511 - __main__ - ERROR - 加载模型出错: [Errno 2] No such file or directory: 'd:\\sam2-main\\checkpoints\\sam2.1_hiera_tiny.pt'
Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3550, in load_model
    self.model = build_sam2(config_path, temp_ckpt_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 167, in _load_checkpoint
    missing_keys, unexpected_keys = model.load_state_dict(sd)
                                    ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\nn\modules\module.py", line 2584, in load_state_dict
    raise RuntimeError(
RuntimeError: Error(s) in loading state_dict for SAM2Base:
	Missing key(s) in state_dict: "no_obj_ptr", "no_obj_embed_spatial", "image_encoder.trunk.blocks.1.proj.weight", "image_encoder.trunk.blocks.1.proj.bias", "image_encoder.trunk.blocks.3.proj.weight", "image_encoder.trunk.blocks.3.proj.bias", "image_encoder.trunk.blocks.10.proj.weight", "image_encoder.trunk.blocks.10.proj.bias", "mask_downsample.weight", "mask_downsample.bias", "memory_attention.layers.0.self_attn.q_proj.weight", "memory_attention.layers.0.self_attn.q_proj.bias", "memory_attention.layers.0.self_attn.k_proj.weight", "memory_attention.layers.0.self_attn.k_proj.bias", "memory_attention.layers.0.self_attn.v_proj.weight", "memory_attention.layers.0.self_attn.v_proj.bias", "memory_attention.layers.0.self_attn.out_proj.weight", "memory_attention.layers.0.self_attn.out_proj.bias", "memory_attention.layers.0.cross_attn_image.q_proj.weight", "memory_attention.layers.0.cross_attn_image.q_proj.bias", "memory_attention.layers.0.cross_attn_image.k_proj.weight", "memory_attention.layers.0.cross_attn_image.k_proj.bias", "memory_attention.layers.0.cross_attn_image.v_proj.weight", "memory_attention.layers.0.cross_attn_image.v_proj.bias", "memory_attention.layers.0.cross_attn_image.out_proj.weight", "memory_attention.layers.0.cross_attn_image.out_proj.bias", "memory_attention.layers.0.linear1.weight", "memory_attention.layers.0.linear1.bias", "memory_attention.layers.0.linear2.weight", "memory_attention.layers.0.linear2.bias", "memory_attention.layers.0.norm1.weight", "memory_attention.layers.0.norm1.bias", "memory_attention.layers.0.norm2.weight", "memory_attention.layers.0.norm2.bias", "memory_attention.layers.0.norm3.weight", "memory_attention.layers.0.norm3.bias", "memory_attention.layers.1.self_attn.q_proj.weight", "memory_attention.layers.1.self_attn.q_proj.bias", "memory_attention.layers.1.self_attn.k_proj.weight", "memory_attention.layers.1.self_attn.k_proj.bias", "memory_attention.layers.1.self_attn.v_proj.weight", "memory_attention.layers.1.self_attn.v_proj.bias", "memory_attention.layers.1.self_attn.out_proj.weight", "memory_attention.layers.1.self_attn.out_proj.bias", "memory_attention.layers.1.cross_attn_image.q_proj.weight", "memory_attention.layers.1.cross_attn_image.q_proj.bias", "memory_attention.layers.1.cross_attn_image.k_proj.weight", "memory_attention.layers.1.cross_attn_image.k_proj.bias", "memory_attention.layers.1.cross_attn_image.v_proj.weight", "memory_attention.layers.1.cross_attn_image.v_proj.bias", "memory_attention.layers.1.cross_attn_image.out_proj.weight", "memory_attention.layers.1.cross_attn_image.out_proj.bias", "memory_attention.layers.1.linear1.weight", "memory_attention.layers.1.linear1.bias", "memory_attention.layers.1.linear2.weight", "memory_attention.layers.1.linear2.bias", "memory_attention.layers.1.norm1.weight", "memory_attention.layers.1.norm1.bias", "memory_attention.layers.1.norm2.weight", "memory_attention.layers.1.norm2.bias", "memory_attention.layers.1.norm3.weight", "memory_attention.layers.1.norm3.bias", "memory_attention.layers.2.self_attn.q_proj.weight", "memory_attention.layers.2.self_attn.q_proj.bias", "memory_attention.layers.2.self_attn.k_proj.weight", "memory_attention.layers.2.self_attn.k_proj.bias", "memory_attention.layers.2.self_attn.v_proj.weight", "memory_attention.layers.2.self_attn.v_proj.bias", "memory_attention.layers.2.self_attn.out_proj.weight", "memory_attention.layers.2.self_attn.out_proj.bias", "memory_attention.layers.2.cross_attn_image.q_proj.weight", "memory_attention.layers.2.cross_attn_image.q_proj.bias", "memory_attention.layers.2.cross_attn_image.k_proj.weight", "memory_attention.layers.2.cross_attn_image.k_proj.bias", "memory_attention.layers.2.cross_attn_image.v_proj.weight", "memory_attention.layers.2.cross_attn_image.v_proj.bias", "memory_attention.layers.2.cross_attn_image.out_proj.weight", "memory_attention.layers.2.cross_attn_image.out_proj.bias", "memory_attention.layers.2.linear1.weight", "memory_attention.layers.2.linear1.bias", "memory_attention.layers.2.linear2.weight", "memory_attention.layers.2.linear2.bias", "memory_attention.layers.2.norm1.weight", "memory_attention.layers.2.norm1.bias", "memory_attention.layers.2.norm2.weight", "memory_attention.layers.2.norm2.bias", "memory_attention.layers.2.norm3.weight", "memory_attention.layers.2.norm3.bias", "memory_attention.layers.3.self_attn.q_proj.weight", "memory_attention.layers.3.self_attn.q_proj.bias", "memory_attention.layers.3.self_attn.k_proj.weight", "memory_attention.layers.3.self_attn.k_proj.bias", "memory_attention.layers.3.self_attn.v_proj.weight", "memory_attention.layers.3.self_attn.v_proj.bias", "memory_attention.layers.3.self_attn.out_proj.weight", "memory_attention.layers.3.self_attn.out_proj.bias", "memory_attention.layers.3.cross_attn_image.q_proj.weight", "memory_attention.layers.3.cross_attn_image.q_proj.bias", "memory_attention.layers.3.cross_attn_image.k_proj.weight", "memory_attention.layers.3.cross_attn_image.k_proj.bias", "memory_attention.layers.3.cross_attn_image.v_proj.weight", "memory_attention.layers.3.cross_attn_image.v_proj.bias", "memory_attention.layers.3.cross_attn_image.out_proj.weight", "memory_attention.layers.3.cross_attn_image.out_proj.bias", "memory_attention.layers.3.linear1.weight", "memory_attention.layers.3.linear1.bias", "memory_attention.layers.3.linear2.weight", "memory_attention.layers.3.linear2.bias", "memory_attention.layers.3.norm1.weight", "memory_attention.layers.3.norm1.bias", "memory_attention.layers.3.norm2.weight", "memory_attention.layers.3.norm2.bias", "memory_attention.layers.3.norm3.weight", "memory_attention.layers.3.norm3.bias", "memory_attention.norm.weight", "memory_attention.norm.bias", "sam_mask_decoder.obj_score_token.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.weight", "sam_mask_decoder.pred_obj_score_head.layers.0.bias", "sam_mask_decoder.pred_obj_score_head.layers.1.weight", "sam_mask_decoder.pred_obj_score_head.layers.1.bias", "sam_mask_decoder.pred_obj_score_head.layers.2.weight", "sam_mask_decoder.pred_obj_score_head.layers.2.bias", "obj_ptr_proj.layers.0.weight", "obj_ptr_proj.layers.0.bias", "obj_ptr_proj.layers.1.weight", "obj_ptr_proj.layers.1.bias", "obj_ptr_proj.layers.2.weight", "obj_ptr_proj.layers.2.bias", "obj_ptr_tpos_proj.weight", "obj_ptr_tpos_proj.bias". 
	Unexpected key(s) in state_dict: "image_encoder.trunk.blocks.12.norm1.weight", "image_encoder.trunk.blocks.12.norm1.bias", "image_encoder.trunk.blocks.12.attn.qkv.weight", "image_encoder.trunk.blocks.12.attn.qkv.bias", "image_encoder.trunk.blocks.12.attn.proj.weight", "image_encoder.trunk.blocks.12.attn.proj.bias", "image_encoder.trunk.blocks.12.norm2.weight", "image_encoder.trunk.blocks.12.norm2.bias", "image_encoder.trunk.blocks.12.mlp.layers.0.weight", "image_encoder.trunk.blocks.12.mlp.layers.0.bias", "image_encoder.trunk.blocks.12.mlp.layers.1.weight", "image_encoder.trunk.blocks.12.mlp.layers.1.bias", "image_encoder.trunk.blocks.13.norm1.weight", "image_encoder.trunk.blocks.13.norm1.bias", "image_encoder.trunk.blocks.13.attn.qkv.weight", "image_encoder.trunk.blocks.13.attn.qkv.bias", "image_encoder.trunk.blocks.13.attn.proj.weight", "image_encoder.trunk.blocks.13.attn.proj.bias", "image_encoder.trunk.blocks.13.norm2.weight", "image_encoder.trunk.blocks.13.norm2.bias", "image_encoder.trunk.blocks.13.mlp.layers.0.weight", "image_encoder.trunk.blocks.13.mlp.layers.0.bias", "image_encoder.trunk.blocks.13.mlp.layers.1.weight", "image_encoder.trunk.blocks.13.mlp.layers.1.bias", "image_encoder.trunk.blocks.14.norm1.weight", "image_encoder.trunk.blocks.14.norm1.bias", "image_encoder.trunk.blocks.14.attn.qkv.weight", "image_encoder.trunk.blocks.14.attn.qkv.bias", "image_encoder.trunk.blocks.14.attn.proj.weight", "image_encoder.trunk.blocks.14.attn.proj.bias", "image_encoder.trunk.blocks.14.norm2.weight", "image_encoder.trunk.blocks.14.norm2.bias", "image_encoder.trunk.blocks.14.mlp.layers.0.weight", "image_encoder.trunk.blocks.14.mlp.layers.0.bias", "image_encoder.trunk.blocks.14.mlp.layers.1.weight", "image_encoder.trunk.blocks.14.mlp.layers.1.bias", "image_encoder.trunk.blocks.15.norm1.weight", "image_encoder.trunk.blocks.15.norm1.bias", "image_encoder.trunk.blocks.15.attn.qkv.weight", "image_encoder.trunk.blocks.15.attn.qkv.bias", "image_encoder.trunk.blocks.15.attn.proj.weight", "image_encoder.trunk.blocks.15.attn.proj.bias", "image_encoder.trunk.blocks.15.norm2.weight", "image_encoder.trunk.blocks.15.norm2.bias", "image_encoder.trunk.blocks.15.mlp.layers.0.weight", "image_encoder.trunk.blocks.15.mlp.layers.0.bias", "image_encoder.trunk.blocks.15.mlp.layers.1.weight", "image_encoder.trunk.blocks.15.mlp.layers.1.bias", "image_encoder.trunk.blocks.16.norm1.weight", "image_encoder.trunk.blocks.16.norm1.bias", "image_encoder.trunk.blocks.16.attn.qkv.weight", "image_encoder.trunk.blocks.16.attn.qkv.bias", "image_encoder.trunk.blocks.16.attn.proj.weight", "image_encoder.trunk.blocks.16.attn.proj.bias", "image_encoder.trunk.blocks.16.norm2.weight", "image_encoder.trunk.blocks.16.norm2.bias", "image_encoder.trunk.blocks.16.mlp.layers.0.weight", "image_encoder.trunk.blocks.16.mlp.layers.0.bias", "image_encoder.trunk.blocks.16.mlp.layers.1.weight", "image_encoder.trunk.blocks.16.mlp.layers.1.bias", "image_encoder.trunk.blocks.17.norm1.weight", "image_encoder.trunk.blocks.17.norm1.bias", "image_encoder.trunk.blocks.17.attn.qkv.weight", "image_encoder.trunk.blocks.17.attn.qkv.bias", "image_encoder.trunk.blocks.17.attn.proj.weight", "image_encoder.trunk.blocks.17.attn.proj.bias", "image_encoder.trunk.blocks.17.norm2.weight", "image_encoder.trunk.blocks.17.norm2.bias", "image_encoder.trunk.blocks.17.mlp.layers.0.weight", "image_encoder.trunk.blocks.17.mlp.layers.0.bias", "image_encoder.trunk.blocks.17.mlp.layers.1.weight", "image_encoder.trunk.blocks.17.mlp.layers.1.bias", "image_encoder.trunk.blocks.18.norm1.weight", "image_encoder.trunk.blocks.18.norm1.bias", "image_encoder.trunk.blocks.18.attn.qkv.weight", "image_encoder.trunk.blocks.18.attn.qkv.bias", "image_encoder.trunk.blocks.18.attn.proj.weight", "image_encoder.trunk.blocks.18.attn.proj.bias", "image_encoder.trunk.blocks.18.norm2.weight", "image_encoder.trunk.blocks.18.norm2.bias", "image_encoder.trunk.blocks.18.mlp.layers.0.weight", "image_encoder.trunk.blocks.18.mlp.layers.0.bias", "image_encoder.trunk.blocks.18.mlp.layers.1.weight", "image_encoder.trunk.blocks.18.mlp.layers.1.bias", "image_encoder.trunk.blocks.19.norm1.weight", "image_encoder.trunk.blocks.19.norm1.bias", "image_encoder.trunk.blocks.19.attn.qkv.weight", "image_encoder.trunk.blocks.19.attn.qkv.bias", "image_encoder.trunk.blocks.19.attn.proj.weight", "image_encoder.trunk.blocks.19.attn.proj.bias", "image_encoder.trunk.blocks.19.norm2.weight", "image_encoder.trunk.blocks.19.norm2.bias", "image_encoder.trunk.blocks.19.mlp.layers.0.weight", "image_encoder.trunk.blocks.19.mlp.layers.0.bias", "image_encoder.trunk.blocks.19.mlp.layers.1.weight", "image_encoder.trunk.blocks.19.mlp.layers.1.bias", "image_encoder.trunk.blocks.20.norm1.weight", "image_encoder.trunk.blocks.20.norm1.bias", "image_encoder.trunk.blocks.20.attn.qkv.weight", "image_encoder.trunk.blocks.20.attn.qkv.bias", "image_encoder.trunk.blocks.20.attn.proj.weight", "image_encoder.trunk.blocks.20.attn.proj.bias", "image_encoder.trunk.blocks.20.norm2.weight", "image_encoder.trunk.blocks.20.norm2.bias", "image_encoder.trunk.blocks.20.mlp.layers.0.weight", "image_encoder.trunk.blocks.20.mlp.layers.0.bias", "image_encoder.trunk.blocks.20.mlp.layers.1.weight", "image_encoder.trunk.blocks.20.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.norm1.weight", "image_encoder.trunk.blocks.21.norm1.bias", "image_encoder.trunk.blocks.21.attn.qkv.weight", "image_encoder.trunk.blocks.21.attn.qkv.bias", "image_encoder.trunk.blocks.21.attn.proj.weight", "image_encoder.trunk.blocks.21.attn.proj.bias", "image_encoder.trunk.blocks.21.norm2.weight", "image_encoder.trunk.blocks.21.norm2.bias", "image_encoder.trunk.blocks.21.mlp.layers.0.weight", "image_encoder.trunk.blocks.21.mlp.layers.0.bias", "image_encoder.trunk.blocks.21.mlp.layers.1.weight", "image_encoder.trunk.blocks.21.mlp.layers.1.bias", "image_encoder.trunk.blocks.21.proj.weight", "image_encoder.trunk.blocks.21.proj.bias", "image_encoder.trunk.blocks.22.norm1.weight", "image_encoder.trunk.blocks.22.norm1.bias", "image_encoder.trunk.blocks.22.attn.qkv.weight", "image_encoder.trunk.blocks.22.attn.qkv.bias", "image_encoder.trunk.blocks.22.attn.proj.weight", "image_encoder.trunk.blocks.22.attn.proj.bias", "image_encoder.trunk.blocks.22.norm2.weight", "image_encoder.trunk.blocks.22.norm2.bias", "image_encoder.trunk.blocks.22.mlp.layers.0.weight", "image_encoder.trunk.blocks.22.mlp.layers.0.bias", "image_encoder.trunk.blocks.22.mlp.layers.1.weight", "image_encoder.trunk.blocks.22.mlp.layers.1.bias", "image_encoder.trunk.blocks.23.norm1.weight", "image_encoder.trunk.blocks.23.norm1.bias", "image_encoder.trunk.blocks.23.attn.qkv.weight", "image_encoder.trunk.blocks.23.attn.qkv.bias", "image_encoder.trunk.blocks.23.attn.proj.weight", "image_encoder.trunk.blocks.23.attn.proj.bias", "image_encoder.trunk.blocks.23.norm2.weight", "image_encoder.trunk.blocks.23.norm2.bias", "image_encoder.trunk.blocks.23.mlp.layers.0.weight", "image_encoder.trunk.blocks.23.mlp.layers.0.bias", "image_encoder.trunk.blocks.23.mlp.layers.1.weight", "image_encoder.trunk.blocks.23.mlp.layers.1.bias", "image_encoder.trunk.blocks.2.proj.weight", "image_encoder.trunk.blocks.2.proj.bias", "image_encoder.trunk.blocks.5.proj.weight", "image_encoder.trunk.blocks.5.proj.bias". 
	size mismatch for image_encoder.trunk.pos_embed: copying a param with shape torch.Size([1, 112, 14, 14]) from checkpoint, the shape in current model is torch.Size([1, 96, 7, 7]).
	size mismatch for image_encoder.trunk.pos_embed_window: copying a param with shape torch.Size([1, 112, 8, 8]) from checkpoint, the shape in current model is torch.Size([1, 96, 8, 8]).
	size mismatch for image_encoder.trunk.patch_embed.proj.weight: copying a param with shape torch.Size([112, 3, 7, 7]) from checkpoint, the shape in current model is torch.Size([96, 3, 7, 7]).
	size mismatch for image_encoder.trunk.patch_embed.proj.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.norm1.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.norm1.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.attn.qkv.weight: copying a param with shape torch.Size([336, 112]) from checkpoint, the shape in current model is torch.Size([288, 96]).
	size mismatch for image_encoder.trunk.blocks.0.attn.qkv.bias: copying a param with shape torch.Size([336]) from checkpoint, the shape in current model is torch.Size([288]).
	size mismatch for image_encoder.trunk.blocks.0.attn.proj.weight: copying a param with shape torch.Size([112, 112]) from checkpoint, the shape in current model is torch.Size([96, 96]).
	size mismatch for image_encoder.trunk.blocks.0.attn.proj.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.norm2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.norm2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.0.mlp.layers.0.weight: copying a param with shape torch.Size([448, 112]) from checkpoint, the shape in current model is torch.Size([384, 96]).
	size mismatch for image_encoder.trunk.blocks.0.mlp.layers.0.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.0.mlp.layers.1.weight: copying a param with shape torch.Size([112, 448]) from checkpoint, the shape in current model is torch.Size([96, 384]).
	size mismatch for image_encoder.trunk.blocks.0.mlp.layers.1.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.1.norm1.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.1.norm1.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([96]).
	size mismatch for image_encoder.trunk.blocks.1.attn.qkv.weight: copying a param with shape torch.Size([336, 112]) from checkpoint, the shape in current model is torch.Size([576, 96]).
	size mismatch for image_encoder.trunk.blocks.1.attn.qkv.bias: copying a param with shape torch.Size([336]) from checkpoint, the shape in current model is torch.Size([576]).
	size mismatch for image_encoder.trunk.blocks.1.attn.proj.weight: copying a param with shape torch.Size([112, 112]) from checkpoint, the shape in current model is torch.Size([192, 192]).
	size mismatch for image_encoder.trunk.blocks.1.attn.proj.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.1.norm2.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.1.norm2.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.1.mlp.layers.0.weight: copying a param with shape torch.Size([448, 112]) from checkpoint, the shape in current model is torch.Size([768, 192]).
	size mismatch for image_encoder.trunk.blocks.1.mlp.layers.0.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.1.mlp.layers.1.weight: copying a param with shape torch.Size([112, 448]) from checkpoint, the shape in current model is torch.Size([192, 768]).
	size mismatch for image_encoder.trunk.blocks.1.mlp.layers.1.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.norm1.weight: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.norm1.bias: copying a param with shape torch.Size([112]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.attn.qkv.weight: copying a param with shape torch.Size([672, 112]) from checkpoint, the shape in current model is torch.Size([576, 192]).
	size mismatch for image_encoder.trunk.blocks.2.attn.qkv.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([576]).
	size mismatch for image_encoder.trunk.blocks.2.attn.proj.weight: copying a param with shape torch.Size([224, 224]) from checkpoint, the shape in current model is torch.Size([192, 192]).
	size mismatch for image_encoder.trunk.blocks.2.attn.proj.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.norm2.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.norm2.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.2.mlp.layers.0.weight: copying a param with shape torch.Size([896, 224]) from checkpoint, the shape in current model is torch.Size([768, 192]).
	size mismatch for image_encoder.trunk.blocks.2.mlp.layers.0.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.2.mlp.layers.1.weight: copying a param with shape torch.Size([224, 896]) from checkpoint, the shape in current model is torch.Size([192, 768]).
	size mismatch for image_encoder.trunk.blocks.2.mlp.layers.1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.3.norm1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.3.norm1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([192]).
	size mismatch for image_encoder.trunk.blocks.3.attn.qkv.weight: copying a param with shape torch.Size([672, 224]) from checkpoint, the shape in current model is torch.Size([1152, 192]).
	size mismatch for image_encoder.trunk.blocks.3.attn.qkv.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.3.attn.proj.weight: copying a param with shape torch.Size([224, 224]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.3.attn.proj.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.3.norm2.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.3.norm2.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.3.mlp.layers.0.weight: copying a param with shape torch.Size([896, 224]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.3.mlp.layers.0.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.3.mlp.layers.1.weight: copying a param with shape torch.Size([224, 896]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.3.mlp.layers.1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.norm1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.norm1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.attn.qkv.weight: copying a param with shape torch.Size([672, 224]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.4.attn.qkv.bias: copying a param with shape torch.Size([672]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.4.attn.proj.weight: copying a param with shape torch.Size([224, 224]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.4.attn.proj.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.norm2.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.norm2.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.4.mlp.layers.0.weight: copying a param with shape torch.Size([896, 224]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.4.mlp.layers.0.bias: copying a param with shape torch.Size([896]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.4.mlp.layers.1.weight: copying a param with shape torch.Size([224, 896]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.4.mlp.layers.1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.norm1.weight: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.norm1.bias: copying a param with shape torch.Size([224]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.attn.qkv.weight: copying a param with shape torch.Size([1344, 224]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.5.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.5.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.5.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.5.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.5.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.5.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.5.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.6.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.6.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.6.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.6.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.6.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.6.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.6.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.7.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.7.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.7.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.7.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.7.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.7.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.7.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.8.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.8.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.8.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.8.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.8.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.8.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.8.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([1152, 384]).
	size mismatch for image_encoder.trunk.blocks.9.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([1152]).
	size mismatch for image_encoder.trunk.blocks.9.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([384, 384]).
	size mismatch for image_encoder.trunk.blocks.9.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.9.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([1536, 384]).
	size mismatch for image_encoder.trunk.blocks.9.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([1536]).
	size mismatch for image_encoder.trunk.blocks.9.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([384, 1536]).
	size mismatch for image_encoder.trunk.blocks.9.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.10.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.10.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([384]).
	size mismatch for image_encoder.trunk.blocks.10.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([2304, 384]).
	size mismatch for image_encoder.trunk.blocks.10.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([2304]).
	size mismatch for image_encoder.trunk.blocks.10.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for image_encoder.trunk.blocks.10.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.10.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.10.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.10.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for image_encoder.trunk.blocks.10.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for image_encoder.trunk.blocks.10.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for image_encoder.trunk.blocks.10.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.norm1.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.norm1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.attn.qkv.weight: copying a param with shape torch.Size([1344, 448]) from checkpoint, the shape in current model is torch.Size([2304, 768]).
	size mismatch for image_encoder.trunk.blocks.11.attn.qkv.bias: copying a param with shape torch.Size([1344]) from checkpoint, the shape in current model is torch.Size([2304]).
	size mismatch for image_encoder.trunk.blocks.11.attn.proj.weight: copying a param with shape torch.Size([448, 448]) from checkpoint, the shape in current model is torch.Size([768, 768]).
	size mismatch for image_encoder.trunk.blocks.11.attn.proj.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.norm2.weight: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.norm2.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.trunk.blocks.11.mlp.layers.0.weight: copying a param with shape torch.Size([1792, 448]) from checkpoint, the shape in current model is torch.Size([3072, 768]).
	size mismatch for image_encoder.trunk.blocks.11.mlp.layers.0.bias: copying a param with shape torch.Size([1792]) from checkpoint, the shape in current model is torch.Size([3072]).
	size mismatch for image_encoder.trunk.blocks.11.mlp.layers.1.weight: copying a param with shape torch.Size([448, 1792]) from checkpoint, the shape in current model is torch.Size([768, 3072]).
	size mismatch for image_encoder.trunk.blocks.11.mlp.layers.1.bias: copying a param with shape torch.Size([448]) from checkpoint, the shape in current model is torch.Size([768]).
	size mismatch for image_encoder.neck.convs.0.conv.weight: copying a param with shape torch.Size([256, 896, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 768, 1, 1]).
	size mismatch for image_encoder.neck.convs.1.conv.weight: copying a param with shape torch.Size([256, 448, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 384, 1, 1]).
	size mismatch for image_encoder.neck.convs.2.conv.weight: copying a param with shape torch.Size([256, 224, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 192, 1, 1]).
	size mismatch for image_encoder.neck.convs.3.conv.weight: copying a param with shape torch.Size([256, 112, 1, 1]) from checkpoint, the shape in current model is torch.Size([256, 96, 1, 1]).

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "d:\sam2-main\sam2_pyqt_app.py", line 3559, in load_model
    self.model = build_sam2(config_path, checkpoint_path, device=self.device)
                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "d:\sam2-main\sam2\build_sam.py", line 93, in build_sam2
    _load_checkpoint(model, ckpt_path)
  File "d:\sam2-main\sam2\build_sam.py", line 166, in _load_checkpoint
    sd = torch.load(ckpt_path, map_location="cpu", weights_only=True)["model"]
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\serialization.py", line 1319, in load
    with _open_file_like(f, "rb") as opened_file:
         ^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\serialization.py", line 659, in _open_file_like
    return _open_file(name_or_buffer, mode)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "D:\Anaconda\envs\sam\Lib\site-packages\torch\serialization.py", line 640, in __init__
    super().__init__(open(name, mode))
                     ^^^^^^^^^^^^^^^^
FileNotFoundError: [Errno 2] No such file or directory: 'd:\\sam2-main\\checkpoints\\sam2.1_hiera_tiny.pt'
2025-11-27 15:05:02,369 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 15:05:03,226 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 15:05:03,233 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:05:03,233 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 15:05:05,403 - __main__ - INFO - 开始加载图像
2025-11-27 15:05:12,823 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-59.bmp
2025-11-27 15:05:12,823 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-59.bmp, 保留视图状态: False
2025-11-27 15:05:12,823 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-59.bmp
2025-11-27 15:05:12,823 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-59.bmp
2025-11-27 15:05:12,832 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 15:05:12,832 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 15:05:12,833 - __main__ - INFO - 图像设置完成
2025-11-27 15:05:12,833 - __main__ - INFO - 已加载图像: 1_1-59.bmp
2025-11-27 15:05:12,834 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 15:05:12,835 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:05:12,835 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 15:05:12,835 - __main__ - INFO - 调用predictor.set_image
2025-11-27 15:05:12,835 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:05:13,035 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:05:13,544 - root - INFO - Image embeddings computed.
2025-11-27 15:05:13,545 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:05:29,051 - __main__ - INFO - 开始加载图像
2025-11-27 15:05:33,224 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-529.bmp
2025-11-27 15:05:33,225 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-529.bmp, 保留视图状态: False
2025-11-27 15:05:33,225 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-529.bmp
2025-11-27 15:05:33,225 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-529.bmp
2025-11-27 15:05:33,226 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 15:05:33,227 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 15:05:33,227 - __main__ - INFO - 图像设置完成
2025-11-27 15:05:33,227 - __main__ - INFO - 已加载图像: 1_1-529.bmp
2025-11-27 15:05:33,229 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 15:05:33,229 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:05:33,229 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 15:05:33,230 - __main__ - INFO - 调用predictor.set_image
2025-11-27 15:05:33,230 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:05:33,259 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:05:33,272 - root - INFO - Image embeddings computed.
2025-11-27 15:05:33,272 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:07:42,278 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 15:07:42,504 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 15:07:42,511 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:07:42,511 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 15:07:42,512 - __main__ - INFO - 调用predictor.set_image，图像形状: (520, 520, 3)
2025-11-27 15:07:42,512 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:07:42,522 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:07:42,536 - root - INFO - Image embeddings computed.
2025-11-27 15:07:42,536 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:07:55,314 - __main__ - INFO - 开始加载图像
2025-11-27 15:07:57,692 - __main__ - INFO - 用户取消了图像选择
2025-11-27 15:08:11,318 - root - INFO - Loaded checkpoint sucessfully
2025-11-27 15:08:12,336 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-11-27 15:08:12,343 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:08:12,343 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-11-27 15:08:12,345 - __main__ - INFO - 调用predictor.set_image，图像形状: (520, 520, 3)
2025-11-27 15:08:12,345 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:08:12,353 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:08:12,367 - root - INFO - Image embeddings computed.
2025-11-27 15:08:12,367 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:08:31,475 - __main__ - INFO - 开始加载图像
2025-11-27 15:08:36,096 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-248.bmp
2025-11-27 15:08:36,096 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-248.bmp, 保留视图状态: False
2025-11-27 15:08:36,096 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-248.bmp
2025-11-27 15:08:36,096 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-248.bmp
2025-11-27 15:08:36,098 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 15:08:36,098 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 15:08:36,098 - __main__ - INFO - 图像设置完成
2025-11-27 15:08:36,098 - __main__ - INFO - 已加载图像: 1_1-248.bmp
2025-11-27 15:08:36,100 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 15:08:36,100 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:08:36,100 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 15:08:36,100 - __main__ - INFO - 调用predictor.set_image
2025-11-27 15:08:36,101 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:08:36,193 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:08:36,207 - root - INFO - Image embeddings computed.
2025-11-27 15:08:36,207 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:08:50,211 - __main__ - INFO - 开始加载图像
2025-11-27 15:08:52,351 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-376.bmp
2025-11-27 15:08:52,351 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-376.bmp, 保留视图状态: False
2025-11-27 15:08:52,351 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-376.bmp
2025-11-27 15:08:52,351 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-376.bmp
2025-11-27 15:08:52,353 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-11-27 15:08:52,353 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-11-27 15:08:52,353 - __main__ - INFO - 图像设置完成
2025-11-27 15:08:52,353 - __main__ - INFO - 已加载图像: 1_1-376.bmp
2025-11-27 15:08:52,355 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-11-27 15:08:52,355 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:08:52,355 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 15:08:52,355 - __main__ - INFO - 调用predictor.set_image
2025-11-27 15:08:52,355 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:08:52,367 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:08:52,379 - root - INFO - Image embeddings computed.
2025-11-27 15:08:52,380 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:09:18,219 - __main__ - INFO - 开始加载图像
2025-11-27 15:09:21,967 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 15:09:21,967 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp, 保留视图状态: False
2025-11-27 15:09:21,968 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 15:09:21,968 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-3999998888687 (27).bmp
2025-11-27 15:09:21,968 - __main__ - INFO - 图像加载成功，尺寸: 400x400
2025-11-27 15:09:21,969 - __main__ - INFO - 图像缩放比例: 0.795, 视图大小: 689x318, 图像大小: 400x400
2025-11-27 15:09:21,969 - __main__ - INFO - 图像设置完成
2025-11-27 15:09:21,969 - __main__ - INFO - 已加载图像: 1_1-3999998888687 (27).bmp
2025-11-27 15:09:21,970 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (400, 400, 3)
2025-11-27 15:09:21,970 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-11-27 15:09:21,970 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-11-27 15:09:21,970 - __main__ - INFO - 调用predictor.set_image
2025-11-27 15:09:21,971 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-11-27 15:09:21,982 - root - INFO - Computing image embeddings for the provided image...
2025-11-27 15:09:21,996 - root - INFO - Image embeddings computed.
2025-11-27 15:09:21,996 - __main__ - INFO - predictor.set_image调用成功
2025-11-27 15:09:41,595 - __main__ - INFO - 开始加载图像
2025-11-27 15:09:49,140 - __main__ - INFO - 用户取消了图像选择
2025-12-01 10:44:42,152 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 10:44:42,385 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 10:49:40,123 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 10:49:40,209 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 10:49:40,402 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 10:49:40,402 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 10:49:40,410 - __main__ - INFO - 开始加载图像
2025-12-01 10:49:41,766 - __main__ - INFO - 用户取消了图像选择
2025-12-01 10:49:47,734 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 10:49:47,941 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 10:49:47,948 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 10:49:47,949 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 11:00:42,053 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 11:00:42,171 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 11:00:43,401 - __main__ - INFO - 开始加载图像
2025-12-01 11:01:29,118 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_0-23.bmp
2025-12-01 11:01:29,119 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_0-23.bmp, 保留视图状态: False
2025-12-01 11:01:29,119 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_0-23.bmp
2025-12-01 11:01:29,119 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_0-23.bmp
2025-12-01 11:01:29,139 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-12-01 11:01:29,140 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-12-01 11:01:29,140 - __main__ - INFO - 图像设置完成
2025-12-01 11:01:29,140 - __main__ - INFO - 已加载图像: 1_0-23.bmp
2025-12-01 11:02:12,733 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 11:02:12,825 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 11:02:12,967 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:02:12,967 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 11:02:12,969 - __main__ - INFO - 调用predictor.set_image，图像形状: (520, 520, 3)
2025-12-01 11:02:12,969 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 11:02:13,048 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 11:02:13,478 - root - INFO - Image embeddings computed.
2025-12-01 11:02:13,478 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 11:03:07,247 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 11:03:07,365 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 11:03:45,416 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 11:03:46,027 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 11:03:46,145 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:03:46,145 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 11:03:46,721 - __main__ - INFO - 开始加载图像
2025-12-01 11:03:52,069 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-33.bmp
2025-12-01 11:03:52,070 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-33.bmp, 保留视图状态: False
2025-12-01 11:03:52,070 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-33.bmp
2025-12-01 11:03:52,070 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-33.bmp
2025-12-01 11:03:52,080 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-12-01 11:03:52,081 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-12-01 11:03:52,081 - __main__ - INFO - 图像设置完成
2025-12-01 11:03:52,081 - __main__ - INFO - 已加载图像: 1_1-33.bmp
2025-12-01 11:03:52,083 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 11:03:52,083 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:03:52,083 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 11:03:52,083 - __main__ - INFO - 调用predictor.set_image
2025-12-01 11:03:52,083 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 11:03:52,284 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 11:03:52,864 - root - INFO - Image embeddings computed.
2025-12-01 11:03:52,864 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 11:03:59,809 - __main__ - INFO - 开始加载图像
2025-12-01 11:04:01,262 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_0-8.bmp
2025-12-01 11:04:01,262 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_0-8.bmp, 保留视图状态: False
2025-12-01 11:04:01,262 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_0-8.bmp
2025-12-01 11:04:01,262 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_0-8.bmp
2025-12-01 11:04:01,267 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-12-01 11:04:01,267 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-12-01 11:04:01,268 - __main__ - INFO - 图像设置完成
2025-12-01 11:04:01,268 - __main__ - INFO - 已加载图像: 1_0-8.bmp
2025-12-01 11:04:01,269 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 11:04:01,270 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:04:01,270 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 11:04:01,270 - __main__ - INFO - 调用predictor.set_image
2025-12-01 11:04:01,270 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 11:04:01,294 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 11:04:01,307 - root - INFO - Image embeddings computed.
2025-12-01 11:04:01,308 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 11:04:20,633 - __main__ - INFO - 开始加载图像
2025-12-01 11:04:27,300 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-245.bmp
2025-12-01 11:04:27,300 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-245.bmp, 保留视图状态: False
2025-12-01 11:04:27,300 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-245.bmp
2025-12-01 11:04:27,301 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-245.bmp
2025-12-01 11:04:27,305 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-12-01 11:04:27,306 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-12-01 11:04:27,306 - __main__ - INFO - 图像设置完成
2025-12-01 11:04:27,306 - __main__ - INFO - 已加载图像: 1_1-245.bmp
2025-12-01 11:04:27,308 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 11:04:27,308 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:04:27,308 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 11:04:27,308 - __main__ - INFO - 调用predictor.set_image
2025-12-01 11:04:27,308 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 11:04:27,320 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 11:04:27,335 - root - INFO - Image embeddings computed.
2025-12-01 11:04:27,335 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 11:04:34,113 - __main__ - INFO - 开始加载图像
2025-12-01 11:04:38,093 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-420.bmp
2025-12-01 11:04:38,093 - __main__ - INFO - 开始设置图像: D:/sam2-main/dataset/images/1_1-420.bmp, 保留视图状态: False
2025-12-01 11:04:38,093 - __main__ - INFO - 文件存在: D:/sam2-main/dataset/images/1_1-420.bmp
2025-12-01 11:04:38,094 - __main__ - INFO - 尝试加载图像: D:/sam2-main/dataset/images/1_1-420.bmp
2025-12-01 11:04:38,097 - __main__ - INFO - 图像加载成功，尺寸: 520x520
2025-12-01 11:04:38,098 - __main__ - INFO - 图像缩放比例: 0.6115384615384616, 视图大小: 689x318, 图像大小: 520x520
2025-12-01 11:04:38,098 - __main__ - INFO - 图像设置完成
2025-12-01 11:04:38,098 - __main__ - INFO - 已加载图像: 1_1-420.bmp
2025-12-01 11:04:38,100 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 11:04:38,100 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:04:38,100 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 11:04:38,100 - __main__ - INFO - 调用predictor.set_image
2025-12-01 11:04:38,101 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 11:04:38,110 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 11:04:38,123 - root - INFO - Image embeddings computed.
2025-12-01 11:04:38,123 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 11:09:00,607 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 11:09:00,760 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 11:10:28,184 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 11:10:28,803 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 11:10:28,921 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 11:10:28,921 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 11:10:28,930 - __main__ - INFO - 开始加载图像
2025-12-01 11:11:20,682 - __main__ - INFO - 用户取消了图像选择
2025-12-01 14:24:24,072 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 14:24:24,233 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 14:24:38,024 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 14:24:38,998 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 14:24:39,162 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 14:24:39,162 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 15:08:44,871 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 15:08:44,994 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 15:08:55,854 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:55,855 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:55,917 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:55,917 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:56,395 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:56,395 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:56,456 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:56,456 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:56,834 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:56,835 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:56,897 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:56,897 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:57,582 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:57,582 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:57,652 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:57,652 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:57,724 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:57,724 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:58,104 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:58,105 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:58,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:58,181 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:58,255 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:58,256 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:59,582 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:59,582 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:59,659 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:59,659 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:08:59,737 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:08:59,738 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:00,021 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:00,021 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:00,093 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:00,094 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:00,309 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:00,309 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:00,975 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:00,975 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,056 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,056 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,134 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,134 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,511 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,511 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,602 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,603 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,683 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,683 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,881 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,881 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:01,961 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:01,961 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,046 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,046 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,124 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,207 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,207 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,281 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,281 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,539 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,540 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,618 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,619 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,862 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,862 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:02,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:02,943 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:03,082 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:03,082 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:03,868 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:03,868 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:03,961 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:03,961 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,373 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,459 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,460 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,540 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,540 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,617 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,617 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,689 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,690 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,763 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,763 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:04,946 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:04,946 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,018 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,018 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,088 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,089 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,246 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,314 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,314 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,383 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,383 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,450 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,451 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,517 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,517 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,800 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,800 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,872 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,872 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:05,954 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:05,954 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:06,196 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:06,196 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:06,293 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:06,293 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:06,604 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:06,604 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:06,683 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:06,683 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:06,759 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:06,759 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:07,076 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:07,077 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:07,149 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:07,149 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:07,220 - PIL.PngImagePlugin - DEBUG - STREAM b'IHDR' 16 13
2025-12-01 15:09:07,220 - PIL.PngImagePlugin - DEBUG - STREAM b'IDAT' 41 65536
2025-12-01 15:09:19,443 - __main__ - INFO - 开始加载图像
2025-12-01 15:09:20,267 - __main__ - INFO - 用户取消了图像选择
2025-12-01 15:09:32,234 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 15:09:32,894 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 15:09:33,013 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:09:33,013 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 15:10:15,458 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 15:10:15,593 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 15:10:16,563 - __main__ - INFO - 开始加载图像
2025-12-01 15:10:18,183 - __main__ - INFO - 用户取消了图像选择
2025-12-01 15:10:20,260 - __main__ - INFO - 开始加载图像
2025-12-01 15:10:21,248 - __main__ - INFO - 用户取消了图像选择
2025-12-01 15:12:38,211 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 15:12:38,333 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 15:12:55,965 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 15:12:56,652 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 15:12:56,784 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:12:56,784 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 15:19:41,575 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 15:19:41,697 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 15:19:46,556 - __main__ - INFO - 开始加载图像
2025-12-01 15:19:48,460 - __main__ - INFO - 用户取消了图像选择
2025-12-01 15:20:56,772 - __main__ - INFO - 开始加载图像
2025-12-01 15:21:01,002 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_0-4.bmp
2025-12-01 15:21:01,006 - __main__ - INFO - 已加载图像: 1_0-4.bmp
2025-12-01 15:21:11,216 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 15:21:11,825 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 15:21:11,943 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:21:11,944 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 15:21:11,946 - __main__ - INFO - 调用predictor.set_image，图像形状: (520, 520, 3)
2025-12-01 15:21:11,946 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 15:21:12,017 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 15:21:12,295 - root - INFO - Image embeddings computed.
2025-12-01 15:21:12,295 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 15:21:41,759 - __main__ - INFO - 启动SAM2应用程序
2025-12-01 15:21:41,882 - __main__ - INFO - 应用程序窗口已显示
2025-12-01 15:21:46,556 - root - INFO - Loaded checkpoint sucessfully
2025-12-01 15:21:47,164 - __main__ - INFO - 创建预测器，模型类型: <class 'sam2.modeling.sam2_base.SAM2Base'>
2025-12-01 15:21:47,283 - __main__ - INFO - 预测器创建成功，类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:21:47,283 - __main__ - INFO - 预测器的set_image方法类型: <class 'method'>
2025-12-01 15:21:47,293 - __main__ - INFO - 开始加载图像
2025-12-01 15:22:34,751 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-204.bmp
2025-12-01 15:22:34,762 - __main__ - INFO - 已加载图像: 1_1-204.bmp
2025-12-01 15:22:34,764 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 15:22:34,764 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:22:34,765 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 15:22:34,765 - __main__ - INFO - 调用predictor.set_image
2025-12-01 15:22:34,765 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 15:22:34,953 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 15:22:35,237 - root - INFO - Image embeddings computed.
2025-12-01 15:22:35,237 - __main__ - INFO - predictor.set_image调用成功
2025-12-01 15:22:58,444 - __main__ - INFO - 开始加载图像
2025-12-01 15:23:06,105 - __main__ - INFO - 选择的图像文件: D:/sam2-main/dataset/images/1_1-293.bmp
2025-12-01 15:23:06,109 - __main__ - INFO - 已加载图像: 1_1-293.bmp
2025-12-01 15:23:06,111 - __main__ - INFO - 图像类型: <class 'numpy.ndarray'>, 形状: (520, 520, 3)
2025-12-01 15:23:06,111 - __main__ - INFO - 预测器类型: <class 'sam2.sam2_image_predictor.SAM2ImagePredictor'>
2025-12-01 15:23:06,111 - __main__ - INFO - set_image属性类型: <class 'method'>
2025-12-01 15:23:06,111 - __main__ - INFO - 调用predictor.set_image
2025-12-01 15:23:06,111 - root - INFO - For numpy array image, we assume (HxWxC) format
2025-12-01 15:23:06,138 - root - INFO - Computing image embeddings for the provided image...
2025-12-01 15:23:06,151 - root - INFO - Image embeddings computed.
2025-12-01 15:23:06,151 - __main__ - INFO - predictor.set_image调用成功
