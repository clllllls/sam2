# @package _global_

scratch:
  resolution: 512
  train_batch_size: 4
  num_train_workers: 4
  max_num_objects: 3
  base_lr: 5.0e-5
  vision_lr: 3.0e-05
  phases_per_epoch: 1
  num_epochs: 50
  
# 图像数据集配置
dataset:
  # 更新为用户提供的实际数据集路径
  img_folder: D:/sam2-main/dataset/images
  gt_folder: D:/sam2-main/dataset/json
  file_list_txt: null
  # 注意：使用绝对路径以避免路径解析问题
# 图像变换
image_transforms:
  train_transforms:
    - _target_: training.dataset.transforms.ComposeAPI
      transforms:
        - _target_: training.dataset.transforms.RandomHorizontalFlip
          consistent_transform: True
        - _target_: training.dataset.transforms.RandomAffine
          degrees: 25
          shear: 20
          image_interpolation: bilinear
          consistent_transform: True
        - _target_: training.dataset.transforms.RandomResizeAPI
          sizes: ${scratch.resolution}
          square: true
          consistent_transform: True
        - _target_: training.dataset.transforms.ColorJitter
          consistent_transform: True
          brightness: 0.1
          contrast: 0.03
          saturation: 0.03
          hue: null
        - _target_: training.dataset.transforms.RandomGrayscale
          p: 0.05
          consistent_transform: True
        - _target_: training.dataset.transforms.ToTensorAPI
        - _target_: training.dataset.transforms.NormalizeAPI
          mean: [0.485, 0.456, 0.406]
          std: [0.229, 0.224, 0.225]

trainer:
  _target_: training.trainer.Trainer
  mode: train_only
  max_epochs: ${times:${scratch.num_epochs},${scratch.phases_per_epoch}}
  accelerator: cuda
  seed_value: 123

  # 图像模型配置 - 移除视频相关功能，保留核心图像编码和掩码解码
  model:
    _target_: training.model.sam2.SAM2Train
    image_encoder:
      _target_: sam2.modeling.backbones.image_encoder.ImageEncoder
      scalp: 1
      trunk:
        _target_: sam2.modeling.backbones.hieradet.Hiera
        embed_dim: 112
        num_heads: 2
        drop_path_rate: 0.1
      neck:
        _target_: sam2.modeling.backbones.image_encoder.FpnNeck
        position_encoding:
          _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
          num_pos_feats: 256
          normalize: true
          scale: null
          temperature: 10000
        d_model: 256
        backbone_channel_list: [896, 448, 224, 112]
        fpn_top_down_levels: [2, 3]
        fpn_interp_model: nearest

    # 单帧处理专用记忆模块
    memory_encoder:
      _target_: sam2.modeling.memory_encoder.MemoryEncoder
      out_dim: 64  # 保持默认值64，与预训练权重匹配
      position_encoding:
        _target_: sam2.modeling.position_encoding.PositionEmbeddingSine
        num_pos_feats: 64  # 保持默认值64，与预训练权重匹配
        normalize: true
        scale: null
        temperature: 10000
      mask_downsampler:
          _target_: sam2.modeling.memory_encoder.MaskDownSampler
          kernel_size: 3
          stride: 2
          padding: 1
      fuser:
        _target_: sam2.modeling.memory_encoder.Fuser
        layer:
          _target_: sam2.modeling.memory_encoder.CXBlock
          dim: 256
          kernel_size: 7
          padding: 3
          layer_scale_init_value: 1e-6
          use_dwconv: True
        num_layers: 2

    # 图像训练专用参数
    image_size: ${scratch.resolution}
    sigmoid_scale_for_mem_enc: 20.0
    sigmoid_bias_for_mem_enc: -10.0
    use_mask_input_as_output_without_sam: true
    use_high_res_features_in_sam: true
    multimask_output_in_sam: true
    iou_prediction_use_sigmoid: True
    # 设置为true以避免维度不匹配错误，直接将no_mem_embed添加到特征中
    directly_add_no_mem_embed: true
    
    # 图像训练专用参数
    # 点/框输入参数，优化用于单帧训练
    prob_to_use_pt_input_for_train: 0.7
    prob_to_use_box_input_for_train: 0.7
    prob_to_sample_from_gt_for_train: 0.2
    num_correction_pt_per_frame: 5
    # 单帧训练设置
    num_init_cond_frames_for_train: 1
    num_init_cond_frames_for_eval: 1
    
  # 图像数据集配置
  data:
    train:
      _target_: training.dataset.sam2_datasets.TorchTrainMixedDataset
      phases_per_epoch: ${scratch.phases_per_epoch}
      # 确保batch_sizes与datasets数量匹配
      batch_sizes:
        - ${scratch.train_batch_size}

      datasets:
        - _target_: training.dataset.vos_dataset.VOSDataset
          transforms: ${image_transforms.train_transforms}
          training: true
          video_dataset:
            # 使用自定义的BMP数据集加载器
            _target_: training.dataset.bmp_raw_dataset.BMPRawDataset
            img_folder: ${dataset.img_folder}
            gt_folder: ${dataset.gt_folder}
            file_list_txt: ${dataset.file_list_txt}
            # 这个加载器专门处理BMP图像和多文件JSON标注格式
          sampler:
            _target_: training.dataset.vos_sampler.RandomUniformSampler
            num_frames: 1
            max_num_objects: ${scratch.max_num_objects}
          multiplier: 1
      # 添加dataset_prob以避免除以零错误
      dataset_prob:
        - 1.0
      shuffle: True
      num_workers: ${scratch.num_train_workers}
      pin_memory: True
      drop_last: True
      collate_fn:
        _target_: training.utils.data_utils.collate_fn
        _partial_: true
        dict_key: all
  
  # 优化器配置
  optim:
    amp:
      enabled: True
      amp_dtype: bfloat16

    optimizer:
      _target_: torch.optim.AdamW

    gradient_clip:
      _target_: training.optimizer.GradientClipper
      max_norm: 0.1
      norm_type: 2

    param_group_modifiers:
      - _target_: training.optimizer.layer_decay_param_modifier
        _partial_: True
        layer_decay_value: 0.9
        apply_to: 'image_encoder.trunk'
        overrides:
          - pattern: '*pos_embed*'
            value: 1.0

    options:
      lr:
        - scheduler:
            _target_: fvcore.common.param_scheduler.CosineParamScheduler
            start_value: ${scratch.base_lr}
            end_value: ${divide:${scratch.base_lr},10}
        - scheduler:
            _target_: fvcore.common.param_scheduler.CosineParamScheduler
            start_value: ${scratch.vision_lr}
            end_value: ${divide:${scratch.vision_lr},10}
          param_names:
            - 'image_encoder.*'
      weight_decay:
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.1
        - scheduler:
            _target_: fvcore.common.param_scheduler.ConstantParamScheduler
            value: 0.0
          param_names:
            - '*bias*'
          module_cls_names: ['torch.nn.LayerNorm']

  # 损失函数
  loss:
    all:
      _target_: training.loss_fns.MultiStepMultiMasksAndIous
      weight_dict:
        loss_mask: 10
        loss_dice: 1
        loss_iou: 1
        loss_class: 1
      supervise_all_iou: true
      iou_use_l1_loss: true

  # 分布式配置 - 只保留DistributedConf类支持的参数
  distributed:
    backend: gloo
    find_unused_parameters: true
    timeout_mins: 30

  # 日志配置
  logging:
    tensorboard_writer:
      _target_: training.utils.logger.make_tensorboard_logger
      log_dir:  ${launcher.experiment_log_dir}/tensorboard
      flush_secs: 120
      should_log: True
    log_dir: ${launcher.experiment_log_dir}/logs
    log_freq: 10

  # 检查点配置
  checkpoint:
    save_dir: ${launcher.experiment_log_dir}/checkpoints
    save_freq: 5 # 每5个epoch保存一次检查点
    # 从SAM 2预训练权重初始化
    model_weight_initializer:
      _partial_: True
      _target_: training.utils.checkpoint_utils.load_state_dict_into_model
      strict: False
      ignore_unexpected_keys: ['no_obj_ptr', 'no_obj_embed_spatial', 'mask_downsample.*', 'memory_attention.*', 'sam_mask_decoder.obj_score_token.*', 'sam_mask_decoder.pred_obj_score_head.*', 'obj_ptr_proj.*', 'obj_ptr_tpos_proj.*']
      ignore_missing_keys: null
      
      state_dict:
        _target_: training.utils.checkpoint_utils.load_checkpoint_and_apply_kernels
        checkpoint_path: ../checkpoints/sam2.1_hiera_base_plus.pt
        ckpt_state_dict_keys: ['model']

# 启动器配置
launcher:
  num_nodes: 1
  gpus_per_node: 1
  experiment_log_dir: ./logs/image_training

# 提交配置
submitit:
  partition: null
  account: null
  qos: null
  cpus_per_task: 4
  use_cluster: false
  timeout_hour: 24
  name: sam2-image-training
  port_range: [10000, 20000]
